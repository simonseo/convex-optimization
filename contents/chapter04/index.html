<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <style>
    .MathJax {
      padding: 2em 0.3em;
      overflow-x: auto;
      overflow-y: hidden;
    }
@media print {

    .container {
        padding: 0;
        max-width: unset;
        break-after: page;
        break-before: page;
    }
    .content {
        padding: 0;
    }
    .masthead {
        display: none;
    }
    .sidebar-toggle {
        display: none;
    }


}
  </style>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

  <title>
    
      Convex Optimization Basis &middot; 모두를 위한 컨벡스 최적화
    
  </title>

  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="/public/css/github-markdown.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="122x144" href="https://convex-optimization-for-all.github.io/public/logo.png">
  <link rel="shortcut icon" href="https://convex-optimization-for-all.github.io/public/convex-logo-144x144.png">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://convex-optimization-for-all.github.io/atom.xml">

  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-189737072-1', 'auto');
    ga('send', 'pageview');
  </script>
  
</head>


  <body class="sidebar-overlay">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>모두를 위한 컨벡스 최적화</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/">Home</a>

    

    
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter01/">01. Introduction</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter02/">02. Convex Sets</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter03/">03. Convex Functions</a>
        
      
    
      
        
          <a class="sidebar-nav-item active" href="https://convex-optimization-for-all.github.io/contents/chapter04/">04. Convex Optimization Basis</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter05/">05. Canonical Problems</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter06/">06. Gradient Descent</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter07/">07. Subgradient</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter08/">08. Subgradient Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter09/">09. Proximal Gradient Descent and Acceleration</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter10/">10. Duality in Linear Programs</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter11/">11. Duality in General Programs</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter12/">12. KKT Conditions</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter13/">13. Duality uses and correspondences</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter14/">14. Newton's Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter15/">15. Barrier Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter16/">16. Duality Revisited</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter17/">17. Primal-Dual Interior-Point Methods</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter18/">18. Quasi-Newton Methods</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter19/">19. Proximal Netwon Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter20/">20. Dual Methods</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter21/">21. Alternating Direction Method of Mulipliers</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter22/">22. Conditional Gradient Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter23/">23. Coordinate Descent</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter24/">24.  Mixed Integer Programming 1</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter25/">25.  Mixed Integer Programming 2</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/reference/">26. Reference</a>
        
      
    

    <span class="sidebar-nav-item">Currently v1.1.0</span>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2022. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap github-md-body">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">모두를 위한 컨벡스 최적화</a>
            <small></small>
          </h3>
          <a class="github-logo__wrapper" target="_blank" href="https://github.com/convex-optimization-for-all/convex-optimization-for-all.github.io" titltle="Github">
           <svg class="github-logo" xmlns="http://www.w3.org/2000/svg"  viewBox="0 0 48 48"><linearGradient id="rL2wppHyxHVbobwndsT6Ca" x1="4" x2="44" y1="23.508" y2="23.508" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#4c4c4c"/><stop offset="1" stop-color="#343434"/></linearGradient><path fill="url(#rL2wppHyxHVbobwndsT6Ca)" d="M24,4C12.954,4,4,12.954,4,24c0,8.887,5.801,16.411,13.82,19.016h12.36	C38.199,40.411,44,32.887,44,24C44,12.954,35.046,4,24,4z"/><path d="M30.01,41.996L30,36.198c0-0.939-0.22-1.856-0.642-2.687c5.641-1.133,8.386-4.468,8.386-10.177	c0-2.255-0.665-4.246-1.976-5.92c0.1-0.317,0.174-0.645,0.22-0.981c0.188-1.369-0.023-2.264-0.193-2.984l-0.027-0.116	c-0.186-0.796-0.409-1.364-0.418-1.388l-0.111-0.282l-0.111-0.282l-0.302-0.032l-0.303-0.032c0,0-0.199-0.021-0.501-0.021	c-0.419,0-1.04,0.042-1.627,0.241l-0.196,0.066c-0.74,0.249-1.439,0.485-2.417,1.069c-0.286,0.171-0.599,0.366-0.934,0.584	C27.334,12.881,25.705,12.69,24,12.69c-1.722,0-3.365,0.192-4.889,0.571c-0.339-0.22-0.654-0.417-0.942-0.589	c-0.978-0.584-1.677-0.819-2.417-1.069l-0.196-0.066c-0.585-0.199-1.207-0.241-1.626-0.241c-0.302,0-0.501,0.021-0.501,0.021	l-0.302,0.032l-0.3,0.031l-0.112,0.281l-0.113,0.283c-0.01,0.026-0.233,0.594-0.419,1.391l-0.027,0.115	c-0.17,0.719-0.381,1.615-0.193,2.983c0.048,0.346,0.125,0.685,0.23,1.011c-1.285,1.666-1.936,3.646-1.936,5.89	c0,5.695,2.748,9.028,8.397,10.17c-0.194,0.388-0.345,0.798-0.452,1.224c-0.197,0.067-0.378,0.112-0.538,0.137	c-0.238,0.036-0.487,0.054-0.739,0.054c-0.686,0-1.225-0.134-1.435-0.259c-0.313-0.186-0.872-0.727-1.414-1.518	c-0.463-0.675-1.185-1.558-1.992-1.927c-0.698-0.319-1.437-0.502-2.029-0.502c-0.138,0-0.265,0.01-0.376,0.028	c-0.517,0.082-0.949,0.366-1.184,0.78c-0.203,0.357-0.235,0.773-0.088,1.141c0.219,0.548,0.851,0.985,1.343,1.255	c0.242,0.133,0.765,0.619,1.07,1.109c0.229,0.368,0.335,0.63,0.482,0.992c0.087,0.215,0.183,0.449,0.313,0.732	c0.47,1.022,1.937,1.924,2.103,2.023c0.806,0.483,2.161,0.638,3.157,0.683l0.123,0.003c0,0,0.001,0,0.001,0	c0.24,0,0.57-0.023,1.004-0.071v2.613c0.002,0.529-0.537,0.649-1.25,0.638l0.547,0.184C19.395,43.572,21.645,44,24,44	c2.355,0,4.605-0.428,6.703-1.176l0.703-0.262C30.695,42.538,30.016,42.422,30.01,41.996z" opacity=".05"/><path d="M30.781,42.797c-0.406,0.047-1.281-0.109-1.281-0.795v-5.804c0-1.094-0.328-2.151-0.936-3.052	c5.915-0.957,8.679-4.093,8.679-9.812c0-2.237-0.686-4.194-2.039-5.822c0.137-0.365,0.233-0.75,0.288-1.147	c0.175-1.276-0.016-2.086-0.184-2.801l-0.027-0.116c-0.178-0.761-0.388-1.297-0.397-1.319l-0.111-0.282l-0.303-0.032	c0,0-0.178-0.019-0.449-0.019c-0.381,0-0.944,0.037-1.466,0.215l-0.196,0.066c-0.714,0.241-1.389,0.468-2.321,1.024	c-0.332,0.198-0.702,0.431-1.101,0.694C27.404,13.394,25.745,13.19,24,13.19c-1.762,0-3.435,0.205-4.979,0.61	c-0.403-0.265-0.775-0.499-1.109-0.699c-0.932-0.556-1.607-0.784-2.321-1.024l-0.196-0.066c-0.521-0.177-1.085-0.215-1.466-0.215	c-0.271,0-0.449,0.019-0.449,0.019l-0.302,0.032l-0.113,0.283c-0.009,0.022-0.219,0.558-0.397,1.319l-0.027,0.116	c-0.169,0.715-0.36,1.524-0.184,2.8c0.056,0.407,0.156,0.801,0.298,1.174c-1.327,1.62-1.999,3.567-1.999,5.795	c0,5.703,2.766,8.838,8.686,9.806c-0.395,0.59-0.671,1.255-0.813,1.964c-0.33,0.13-0.629,0.216-0.891,0.256	c-0.263,0.04-0.537,0.06-0.814,0.06c-0.69,0-1.353-0.129-1.69-0.329c-0.44-0.261-1.057-0.914-1.572-1.665	c-0.35-0.51-1.047-1.417-1.788-1.755c-0.635-0.29-1.298-0.457-1.821-0.457c-0.11,0-0.21,0.008-0.298,0.022	c-0.366,0.058-0.668,0.252-0.828,0.534c-0.128,0.224-0.149,0.483-0.059,0.708c0.179,0.448,0.842,0.85,1.119,1.002	c0.335,0.184,0.919,0.744,1.254,1.284c0.251,0.404,0.37,0.697,0.521,1.067c0.085,0.209,0.178,0.437,0.304,0.712	c0.331,0.719,1.353,1.472,1.905,1.803c0.754,0.452,2.154,0.578,2.922,0.612l0.111,0.002c0.299,0,0.8-0.045,1.495-0.135v3.177	c0,0.779-0.991,0.81-1.234,0.81c-0.031,0,0.503,0.184,0.503,0.184C19.731,43.64,21.822,44,24,44c2.178,0,4.269-0.36,6.231-1.003	C30.231,42.997,30.812,42.793,30.781,42.797z" opacity=".07"/><path fill="#fff" d="M36.744,23.334c0-2.31-0.782-4.226-2.117-5.728c0.145-0.325,0.296-0.761,0.371-1.309	c0.172-1.25-0.031-2-0.203-2.734s-0.375-1.25-0.375-1.25s-0.922-0.094-1.703,0.172s-1.453,0.469-2.422,1.047	c-0.453,0.27-0.909,0.566-1.27,0.806C27.482,13.91,25.785,13.69,24,13.69c-1.801,0-3.513,0.221-5.067,0.652	c-0.362-0.241-0.821-0.539-1.277-0.811c-0.969-0.578-1.641-0.781-2.422-1.047s-1.703-0.172-1.703-0.172s-0.203,0.516-0.375,1.25	s-0.375,1.484-0.203,2.734c0.077,0.562,0.233,1.006,0.382,1.333c-1.31,1.493-2.078,3.397-2.078,5.704	c0,5.983,3.232,8.714,9.121,9.435c-0.687,0.726-1.148,1.656-1.303,2.691c-0.387,0.17-0.833,0.33-1.262,0.394	c-1.104,0.167-2.271,0-2.833-0.333s-1.229-1.083-1.729-1.813c-0.422-0.616-1.031-1.331-1.583-1.583	c-0.729-0.333-1.438-0.458-1.833-0.396c-0.396,0.063-0.583,0.354-0.5,0.563c0.083,0.208,0.479,0.521,0.896,0.75	c0.417,0.229,1.063,0.854,1.438,1.458c0.418,0.674,0.5,1.063,0.854,1.833c0.249,0.542,1.101,1.219,1.708,1.583	c0.521,0.313,1.562,0.491,2.688,0.542c0.389,0.018,1.308-0.096,2.083-0.206v3.75c0,0.639-0.585,1.125-1.191,1.013	C19.756,43.668,21.833,44,24,44c2.166,0,4.243-0.332,6.19-0.984C29.585,43.127,29,42.641,29,42.002v-5.804	c0-1.329-0.527-2.53-1.373-3.425C33.473,32.071,36.744,29.405,36.744,23.334z M11.239,32.727c-0.154-0.079-0.237-0.225-0.185-0.328	c0.052-0.103,0.22-0.122,0.374-0.043c0.154,0.079,0.237,0.225,0.185,0.328S11.393,32.806,11.239,32.727z M12.451,33.482	c-0.081,0.088-0.255,0.06-0.389-0.062s-0.177-0.293-0.096-0.381c0.081-0.088,0.255-0.06,0.389,0.062S12.532,33.394,12.451,33.482z M13.205,34.732c-0.102,0.072-0.275,0.005-0.386-0.15s-0.118-0.34-0.016-0.412s0.275-0.005,0.386,0.15	C13.299,34.475,13.307,34.66,13.205,34.732z M14.288,35.673c-0.069,0.112-0.265,0.117-0.437,0.012s-0.256-0.281-0.187-0.393	c0.069-0.112,0.265-0.117,0.437-0.012S14.357,35.561,14.288,35.673z M15.312,36.594c-0.213-0.026-0.371-0.159-0.353-0.297	c0.017-0.138,0.204-0.228,0.416-0.202c0.213,0.026,0.371,0.159,0.353,0.297C15.711,36.529,15.525,36.62,15.312,36.594z M16.963,36.833c-0.227-0.013-0.404-0.143-0.395-0.289c0.009-0.146,0.2-0.255,0.427-0.242c0.227,0.013,0.404,0.143,0.395,0.289	C17.381,36.738,17.19,36.846,16.963,36.833z M18.521,36.677c-0.242,0-0.438-0.126-0.438-0.281s0.196-0.281,0.438-0.281	c0.242,0,0.438,0.126,0.438,0.281S18.762,36.677,18.521,36.677z"/></svg>
          </a>
        </div>
      </div>

      <div class="container content">
        <h1>04. Convex Optimization Basis</h1>






<!-- Get first post and show it -->

<h2 id="convex-optimization-basic">Convex Optimization Basic</h2>

<p>이번 장에서는 Convex Problem의 주요한 성질과 문제의 풀이에 자주 사용하는 몇 가지 테크닉에 대해 알아보도록 한다.</p>


<!-- Remove first element from post_list which is already shown above. -->
  

<!-- List up the posts in the chapter -->
<ul style="list-style: none;">

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_1">04-01 Basic terminology</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_2">04-02 Convex solution sets</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_3">04-03 First order optimality condition</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_4">04-04 Partial optimization</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_5">04-05 Transformations and change of variables</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_6">04-06 Eliminating equality constraints</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_7">04-07 Slack variables</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_8">04-08 Relaxation</a>
    </li>
  
  

</ul>


<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_1"></a>04-01 Basic terminology</h1>
            <h2 id="convex-optimization-basic">Convex Optimization Basic</h2>

<p>Convex optimization 문제에서 사용되는 기본적인 용어들을 살펴보자. <br />
일단 convex optimization 문제는 다음과 같이 정의된다.</p>

<blockquote>
\[\begin{aligned}
&amp;\text{minimize}_{x \in D} &amp;&amp;{f(x)} \\
&amp;\text{subject to} &amp;&amp;{g_{i}(x) \leq 0, \,\,\,\,\, i = 1, \dotsc, m} \\
&amp;&amp;&amp;{h_{j}(x) = 0, \,\,\, j = 1, \dotsc, r},\\\\
\end{aligned}\]
</blockquote>

<blockquote>
  <p>where \(f\) and \(g_{i}\), \(\, \, i=1,\dotsc, m\) are all convex,
\(h_j, \, \, j = 1, \dotsc, r\) are all affine,
and the optimization domain is \(D = dom(f) \cap \bigcap_{i=1}^{m} dom(g_{i}) \cap  \bigcap_{j=1}^r dom(h_{j})\).</p>
</blockquote>

<ul>
  <li>\(f\)는 <strong>criterion</strong> 또는 <strong>objective function</strong>이라 부른다.</li>
  <li>\(g_{i}(x)\)는 <strong>inequality constraint function</strong>이라고 한다.</li>
  <li>\(h_{j}(x)\)는 <strong>equality constraint function</strong>이라고 한다.</li>
  <li>만약 \(x \in D\)이고,
\({g_{i}(x) \leq 0, \, i = 1, \dotsc, m} \,\)와
\({h_{j}(x) = 0, j = 1, \dotsc, r}\)를 만족하면 \(x\)는 <strong>feasible point</strong>다.</li>
  <li>모든 feasible point \(x\)에 대해  \(f(x)\)의 최솟값을 <strong>optimal value</strong>라 부르고, \(f^{\star}\)으로 쓴다.</li>
  <li>\(x\)가 feasible하고 \(f(x) = f^{\star}\)일때, \(x\)는 <strong>optimal</strong>, <strong>solution</strong>, 또는 <strong>minimizer</strong>라 부른다.</li>
  <li>\(x\)가 feasible하고 \(f(x) \le f^{\star} + \epsilon\)일때, \(x\)는 <strong>\(\epsilon\)-suboptimal</strong>이라 부른다.</li>
  <li>\(x\)가 feasible하고 \(g_i(x) = 0\)일때, \(g_i\)는 \(x\)에서 <strong>active</strong>하다고 한다.</li>
  <li>Convex minimization 문제는 concave maximization 문제로 변환할 수 있다.</li>
</ul>

<blockquote>
\[\begin{aligned}
&amp;\text{maximize}_{x \in D} \, \, \, &amp;&amp;-f(x)\\
&amp;\text{subject to} &amp;&amp;g_{i}(x) \leq 0, i = 1, .., m\\
&amp;&amp;&amp;h_{j}(x) = 0, j = 1, \dotsc, r,\\\\
\end{aligned}\]
</blockquote>

<blockquote>
  <p>where \(f\) and \(g_{i}\), \(\, \, i=1,\dotsc, m\) are all convex,
\(h_j, \, \, j = 1, \dotsc, r\) are all affine,
and the optimization domain is \(D = dom(f) \cap \bigcap_{i=1}^{m} dom(g_{i}) \cap  \bigcap_{j=1}^r dom(h_{j})\).</p>
</blockquote>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_2"></a>04-02 Convex solution sets</h1>
            <p>Convex solution set의 성질에 대해 알아보자. <br />
\(X_{opt}\)를 다음과 같이 어떤 convex problem에 대한 solution의 집합이라고 하겠다.</p>

<blockquote>
\[\begin{aligned}
X_{opt} = 
&amp;\text{arg}\min_x &amp;&amp;f(x) \\
&amp;\text{subject to} &amp;&amp;g_{i}(x) \leq 0, i = 1, .., m \\
&amp;&amp;&amp;h_{j}(x) = 0, i = 1, .., r  \\\\
\end{aligned}\]
</blockquote>

<h2 id="key-property1">Key property1</h2>
<blockquote>
  <p>\(X_{opt}\)는 convex set이다.</p>
</blockquote>

<h4 id="proof">Proof</h4>
<blockquote>
  <p>\(x\), \(y\)가 solution일때,</p>
  <ol>
    <li>Domain set \(D\)는 convex set이므로, <br />\(0 \le t \le 1\)에 대해 \(tx+ (1-t)y \in D\)를 만족한다.<br /><br /></li>
    <li>\(g_i, i=1,\dotsc,m\)와 \(h_j, j=1, \dotsc,r\)은 각각 convex, affine function이므로 아래 제약조건을 만족한다. <br /><br />
 \(\begin{aligned}
    g_{i}(tx + (1-t)y) \leq tg_i(x) + (1-t)g_i(y) \leq 0, \\
    h_{j}(tx + (1-t)y) = th_j(x) + (1-t)h_j(y) = 0 \\
 \end{aligned}\)<br /><br /></li>
    <li>\(f\)는 convex function이므로 아래를 만족한다. <br /><br />
 \(\begin{aligned}
   f(tx+(1-t)y) &amp;\leq tf(x) + (1-t)f(y) \\ 
   &amp;= tf^{\star} + (1-t) f^{\star} \\ 
   &amp;= f^{\star}
 \end{aligned}\) <br />
 즉, \(tx + (1-t)y\) 또한 solution이다.</li>
  </ol>
</blockquote>

<h4 id="geometric-interpretation">Geometric interpretation</h4>
<p>Convex function에서의 local optimum은 곧 global optimum이기 때문에 <br />
복수의 element를 가진 solution set이 있다면 이는 아래와 같은 모양일 수 밖에 없다.<br /></p>

<figure class="image" style="align: center;">
<p align="center">
  <img src="/img/chapter_img/chapter04/multiple-optima.png" alt="[Fig1] geometric interpretation of convexity of the solution set" />
  <figcaption style="text-align: center;">[Fig1] geometric interpretation of convexity of the solution set</figcaption>
</p>
</figure>
<p><br /></p>

<h2 id="key-property2">Key property2</h2>
<blockquote>
  <p>\(f\)가 strictly convex이라면 solution은 unique하다. 즉, \(X_{opt}\)는 하나의 element만을 갖는다.</p>
</blockquote>

<p>\(f\)가 strictly convex라는 것은 \(f\)가 다음과 같은 성질을 항상 만족한다는 것과 같다.<br /></p>
<blockquote>
\[f(tx + (1-t)y) &lt; tf(x) + (1-t)f(y),\]

\[\text{where } 0 &lt; t &lt; 1, x \neq y, \text{ and } x, y \in \text{dom } f.\]
</blockquote>

<p>즉, \(f\)는 평평한 구간이 없는 아래로 볼록한 형태이며 \(f\)의 solution은 오직 하나이다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_3"></a>04-03 First order optimality condition</h1>
            <blockquote>
\[\begin{aligned}
&amp;\min_x &amp;&amp;f(x) \\
&amp;\text{subject to} &amp;&amp;x \in C
\end{aligned}\]
</blockquote>

<p>위 convex problem에서 objective function \(f\)가 미분 가능할 때, <br />
아래의 부등식은 optimal point \(x\)에 대한 필요충분 조건이 된다.</p>

<blockquote>
\[\nabla f(x)^{T}(y-x) \geq 0 \\
\text{ for all } y \in C\]
</blockquote>

<p>우리는 이를 <em>first-order condition for optimality</em>라고 부른다. <br />
\(\nabla f(x)^{T}(y-x) = 0\)는 set \(C\)의 접점 x를 지나는 hyperplane이고, <br />
\(- \nabla f(x)\)는 \(x\)에서 optimal point로 이동하는 방향이다. <br /><br />
이때 위의 부등식을 만족한다면 <br />
set \(C\)가 \(- \nabla f(x)\)의 반대방향인 half-space에 포함된다는 것이므로 <br />
\(x\)는 optimal point가 된다.<br /></p>

<figure class="image" style="align: center;">
<p align="center">
  <img src="/img/chapter_img/chapter04/first-order-condition.png" alt="[Fig1] geometric interpretation of first-order condition for optimality [3]" />
  <figcaption style="text-align: center;">[Fig1] geometric interpretation of first-order condition for optimality [3]</figcaption>
</p>
</figure>
<p><br /></p>

<h4 id="important-special-case">Important special case</h4>
<p>\(C = R^n\)일때 (unconstrained optimization일때), <br />
optimality condition은 다음과 같이 정의된다.</p>
<blockquote>
\[\nabla f(x) = 0\]
</blockquote>

<p>마찬가지로 −∇f(x) 는 x에서 optimal point로 이동하는 방향인데, <br />
\(\nabla f(x) = 0\)라는 것은 <br />
\(f\)를 최소화시키기 위해 \(x\)에서 더이상 이동할 곳이 없다는 것과 같다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_4"></a>04-04 Partial optimization</h1>
            <p><a href="/contents/chapter03/2021/02/12/03_02_operations_that_preserve_convexity/">Reminder: </a>
\(C\)가 convex set이고 \(f\)가 \((x,y)\)에 대해 convex일때, \(g(x) = \min_{y \in C} f(x, y)\)는 x에 대해 convex이다.</p>

<p>즉, 위의 성질에 의해 다변수 함수로 구성된 convex problem에서의 partial optimization이 가능하며 이 과정에서 convexity가 유지된다.</p>

<figure class="image" style="align: center;">
<p align="center">
  <img src="/img/chapter_img/chapter04/partial-optimization.png" alt="[Fig1] partial optimization of a convex problem [3]" />
  <figcaption style="text-align: center;">[Fig1] partial optimization of a convex problem [3]</figcaption>
</p>
</figure>
<p><br /></p>

<h4 id="example-hinge-form-of-svms">Example: hinge form of SVMs</h4>
<p>Non-separable set에 대한 SVM 문제는 다음과 같이 정의된다.</p>
<blockquote>
\[\begin{aligned}
&amp;\min_{\beta, \beta_{0}, \xi} &amp;&amp;\frac{1}{2}\|\beta\|_2^2 + C \sum_{i=1}^{n} \xi_{i} \\
&amp;\text{subject to} &amp;&amp;{\xi}_{i} \ge 0, \\ 
&amp;&amp;&amp;y_{i}(x_{i})^T \beta + \beta_{0}) \ge 1 - {\xi}_{i}, \\
&amp;&amp;&amp;i = 1, .., n \\
\end{aligned}\]
</blockquote>

<p>위의 제약조건들은 아래의 제약조건 하나로 표현될 수 있다. <br /></p>
<blockquote>
\[\begin{aligned}
{\xi}_{i} \ge max\{0, 1 - y_{i} (x_{i}^T \beta + \beta_{0})\} \\
\end{aligned}\]
</blockquote>

<p>이때, \(max\{0, 1 - y_{i} (x_{i}^T \beta + \beta_{0})\}\)는 \({\xi}_{i}\)의 하한임을 이용하여 \(\tilde{f}\)를 얻을 수 있다.<br /></p>

<blockquote>
\[\begin{aligned}
\frac{1}{2} \|\beta\|_{2}^{2} + C \sum_{i=1}^{n} {\xi}_{i} &amp;\ge \frac{1}{2} \|\beta\|_{2}^{2} + C \sum_{i=1}^{n} max({0, 1 - y_{i} (x_{i}^T \beta + \beta_{0})})\\
&amp;= \min\{\frac{1}{2} \|\beta\|_{2}^{2} + C \sum_{i=1}^{n} \xi_{i} \quad | \quad \xi_{i} \ge 0, \ y_{i}(x_{i}^T \beta + \beta_{0}) \ge 1 - \xi_{i}, \ i = 1, .., n\} \\
&amp;= \tilde{f}(\beta, \beta_{0}) \\
\end{aligned}\]
</blockquote>

<p>그리고 아래와 같이 \(\tilde{f}\)를 objective function으로 사용함으로써 좀 더 간단한 형태로 solution을 얻을 수 있다. 주어진 문제에서 \(\xi\)가 제거되었고, 또한 constrained problem에서 unconstrained problem으로 변환되었다.</p>

<blockquote>
\[\begin{aligned}
\min_{\beta, \beta_0} \frac{1}{2} \|\beta\|_2^2 + C \sum_{i=1}^{n} max\{0, 1 - y_{i} (x_{i}^{T} \beta + \beta_{0}) \}
\end{aligned}\]
</blockquote>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_5"></a>04-05 Transformations and change of variables</h1>
            <p>목적함수 또는 제약함수는 주어진 optimization problem를 유지하는 선에서 변경될 수 있으며, 때로는 이를 이용해 문제의 “hidden convexity”를 찾아낼 수 있다.</p>

<h4 id="theorem1">Theorem1</h4>
<p>함수 \(h : \mathbb{R} \rightarrow \mathbb{R}\)가 monotone increasing transformation일때, 아래의 관계가 성립한다.</p>

<blockquote>
\[\begin{align}
  &amp;\text{min}_{x} f(x) \text{ subject to } x \in C \\
  \Longleftrightarrow \quad &amp;\text{min}_{x} h(f(x)) \text{ subject to } x \in C
\end{align}\]
</blockquote>

<h4 id="theorem2">Theorem2</h4>
<p>함수 \(\phi: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\)가 일대일 대응 함수이고, \(\phi\)의 상(image)이 feasible set \(C\)를 커버한다면 optimization problem의 변수는 다음과 같이 변경될 수 있다.</p>

<blockquote>
\[\begin{align}
   &amp;\min_{x} f(x) \text{ subject to } x \in C \\\\ 
   \Longleftrightarrow \quad &amp;\min_{y} f(\phi(y)) \text{ subject to } \phi(y) \in C
\end{align}\]
</blockquote>

<h4 id="example-geometric-programming">Example: geometric programming</h4>

<p>함수 \(f: \mathbb{R}\_{++}^n \rightarrow \mathbb{R}\)가 다음과 같은 형태일때 이를 <strong>monomial</strong>이라 부른다.</p>
<blockquote>
\[f(x) = \gamma x_{1}^{a_{1}} x_{2}^{a_{2}} \dotsb x_{n}^{a_{n}} \text{ for } \gamma &gt; 0, a_{1}, \dotsc, a_{n} \in \mathbb{R}.\]
</blockquote>

<p>또한 monomial의 합을 <strong>posynomial</strong>이라 부른다.</p>
<blockquote>
\[g(x) = \sum_{k=1}^{p} \gamma_{k} x_{1}^{a_{k1}} x_{2}^{a_{k2}} \dotsb x_{n}^{a_{kn}} \text{ for } \gamma &gt; 0, a\_1, \dotsc, a_{n} \in \mathbb{R}.\]
</blockquote>

<p><strong>Geometric program</strong>은 다음과 같은 형태로 정의되며, 이는 non-convex problem이다.</p>
<blockquote>
\[\begin{align}
&amp;\min_{x} &amp;&amp;f(x) \\
&amp;\text{subject to } &amp;&amp;g_{i}(x) \leq 1, i = 1, \dotsc, m\\
&amp;&amp;&amp;h_{j}(x) = 1, j = 1, \dotsc, r,\\\\
\end{align}\\\]
</blockquote>

<blockquote>
  <p>where \(f\), \(g_{i}, i=1, \dotsc, m\) are posynomials and \(h_{j}, j=1, \dotsc, r\) are monomials.</p>
</blockquote>

<p>Geometric program이 어떤 convex problem과 동일함을 증명해보자.</p>

<h4 id="proof">Proof:</h4>
<blockquote>
  <p>\(f(x) = \gamma x_{1}^{a_{1}} x_{2}^{a_{2}} \dotsb x_{n}^{a_{n}}\)일때, \(y_{i} = logx_{i}\), \(b=log \gamma\)라 하면 \(f\)는 다음과 같이 변경될 수 있으며, <strong>Theorem2</strong>에 의해 이는 주어진 optimization problem을 동일하게 유지한다.
\(\gamma (e^{y_{1}})^{a_{1}} (e^{y_{2}})^{a_{2}} \dotsb (e^{y_{n}})^{a_{n}} = e^{a^Ty + b}\)</p>

  <p>또한 posynomial은 \(\sum_{k=1}^{p} e^{a_{k}^{Ty} + b_{k}}\)로 나타낼 수 있다.</p>

  <p>이때, <strong>Theorem1</strong>에 의해 이에 log를 취해준 형태인 \(log \big( \sum_{k=1}^{p} e^{a_{k}^{Ty} + b_{k}} \big)\) 또한 optimization problem을 동일하게 유지할 수 있다.</p>

  <p>즉, geometric program은 다음의 문제와도 동일하며 이는 convex problem이다.</p>

\[\begin{align}
&amp;\min_{x} \quad &amp;&amp;{log \big( \sum_{k=1}^{p_{0}} e^{a_{0k}^{Ty} + b_{0k}} \big)} \\
&amp;\text{subject to} &amp;&amp;{
         log \big( \sum_{k=1}^{p_{i}} e^{a_{ik}^{Ty} + b_{ik}} \big)
         \leq 0
         , \quad i = 1, \dotsc, m
}\\
&amp;&amp;&amp;c_{j}^{Ty} + d_{j} = 0, \quad j = 1, \dotsc, r\\\\
\end{align}\]
</blockquote>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_6"></a>04-06 Eliminating equality constraints</h1>
            <p>변수를 변경함으로써 convex problem에서 equality constraints를 소거하는 방법에 대해 알아보겠다.</p>

<blockquote>
\[\begin{aligned}
&amp;\min_{x} &amp;&amp;f(x)\\
&amp;\text{subject to } &amp;&amp;g_{i}(x) \leq 0, i = 1, .., m\\
&amp;&amp;&amp;{Ax = b}.\\
\end{aligned}\]
</blockquote>

<p>임의의 solution \(x_{0}\)에 대해 \(Ax_{0} = b\)이고 \(\text{col}(M) = \text{null}(A)\)이면, equality constraint를 만족하는 임의의 \(x\)를 다음과 같이 표현할 수 있다.</p>
<blockquote>
\[x = My + x_{0}\]
</blockquote>

<p>즉, \(Ax = A(My + x_{0}) = AMy + Ax_{0} = 0 + b = b\)이므로, 주어진 문제의 \(x\)를 \(My+x_{0}\)로 치환하면 equality constraint를 소거할 수 있다.</p>

<p>그러므로 다음의 문제는 최초에 주어진 문제와 동치이다.</p>

<blockquote>
\[\begin{aligned}
&amp;\min_y &amp;&amp;f(My+x_0)\\
&amp;\text{subject to} &amp;&amp;g_{i}(My+x_{0}) \leq 0, i = 1, .., m.\\
\end{aligned}\]
</blockquote>

<p>단, 이와 같은 방법은 다음과 같은 이유들로 사용에 주의해야한다.</p>
<ol>
  <li>\(M\)을 계산하는 비용은 대체로 굉장히 크다.</li>
  <li>\(x\)가 \(y\)보다 더 희소(sparse)하다면 \(y\)를 써서 계산하는 비용이 더 클 수 있다.</li>
</ol>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_7"></a>04-07 Slack variables</h1>
            <p>Slack variable \(s\)를 사용하여 inequality constraint를 equality constraint로 변환하는 방법에 대해 알아보자.</p>

<blockquote>
\[\begin{aligned}
&amp;\min_x &amp;&amp;f(x) \\
&amp;\text{subject to} &amp;&amp;g_{i}(x) \leq 0, i = 1, .., m\\
&amp;&amp;&amp;Ax = b.\\
\end{aligned}\]
</blockquote>

<p>위의 convex problem은 다음의 문제와 동일하다.</p>

<blockquote>
\[\begin{aligned}
&amp;\min_{x, s} &amp;&amp;f(x)\\
&amp;\text{subject to} &amp;&amp;s_{i} \geq 0, i = 1, .., m\\
&amp;&amp;&amp;g_{i}(x) + s_{i} = 0, i = 1,...m\\
&amp;&amp;&amp;Ax = b.\\
\end{aligned}\]
</blockquote>

<p>주의해야 할 점은 \(g_{i}, i = 1, \dotsc, m\)이 affine이 아니라면 위의 문제는 더이상 convex problem이 아니라는 것이다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_8"></a>04-08 Relaxation</h1>
            <p>다음과 같은 문제가 주어졌다고 하자.</p>
<blockquote>
\[\text{min}_{x} \text{ } f(x) \text{  subject to  } x \in C\]
</blockquote>

<p>이때, domain set \(C\)를 \(\tilde{C} \supseteq C\)로 변경하는 것을 <em>Relaxation</em>이라고 한다.</p>
<blockquote>
\[\text{min}_{x} \text{ } f(x) \text{  subject to  } x \in \tilde{C}\]
</blockquote>

<p>\(C\)보다 더 큰 domain set에 대해 최적화하는 것이므로 그 optimal value는 항상 원래의 문제보다 더 작거나 같다.</p>

<h4 id="important-special-case-relaxing-non-affine-equality-constraints">Important special case: relaxing non-affine equality constraints</h4>
<blockquote>
  <p>\(h_{j}(x) = 0, j = 1, \dotsc, r,\) where \(h_{j}, j = 1, \dotsc, r\) are convex but non-affine,
are placed with \(h_{j(x)} \le 0, j = 1, \dotsc, r.\)</p>
</blockquote>

<p>Equality constraint를 inequality constraint로 바꿈으로써 제약조건이 느슨해지고, domain의 크기가 커지는 효과가 발생한다. 주어진 equality constraint가 covex이고 non-affine일때, 이 방법을 이용하여 문제를 convex 문제로 변경하여 풀이할 수 있다. (단, relaxation 이후에도 동일한 solution이 도출됨이 보장되는 경우에 한함.)</p>

        </article>
    </div>
</main>




      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/public/js/script.js'></script>
  </body>
</html>
