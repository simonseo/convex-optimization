<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <style>
    .MathJax {
      padding: 2em 0.3em;
      overflow-x: auto;
      overflow-y: hidden;
    }
@media print {

    .container {
        padding: 0;
        max-width: unset;
        break-after: page;
        break-before: page;
    }
    .content {
        padding: 0;
    }
    .masthead {
        display: none;
    }
    .sidebar-toggle {
        display: none;
    }


}
  </style>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

  <title>
    
      Newton's Method &middot; 모두를 위한 컨벡스 최적화
    
  </title>

  <link rel="stylesheet" href="/convex-optimization/public/css/poole.css">
  <link rel="stylesheet" href="/convex-optimization/public/css/syntax.css">
  <link rel="stylesheet" href="/convex-optimization/public/css/lanyon.css">
  <link rel="stylesheet" href="/convex-optimization/public/css/github-markdown.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="122x144" href="https://simonseo.github.io/convex-optimization/convex-optimization/public/logo.png">
  <link rel="shortcut icon" href="https://simonseo.github.io/convex-optimization/convex-optimization/public/convex-logo-144x144.png">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://simonseo.github.io/convex-optimization/convex-optimization/atom.xml">

  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-189737072-1', 'auto');
    ga('send', 'pageview');
  </script>
  
</head>


  <body class="sidebar-overlay">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>모두를 위한 컨벡스 최적화</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/">Home</a>

    

    
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter01/">01. Introduction</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter02/">02. Convex Sets</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter03/">03. Convex Functions</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter04/">04. Convex Optimization Basis</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter05/">05. Canonical Problems</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter06/">06. Gradient Descent</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter07/">07. Subgradient</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter08/">08. Subgradient Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter09/">09. Proximal Gradient Descent and Acceleration</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter10/">10. Duality in Linear Programs</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter11/">11. Duality in General Programs</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter12/">12. KKT Conditions</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter13/">13. Duality uses and correspondences</a>
        
      
    
      
        
          <a class="sidebar-nav-item active" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter14/">14. Newton's Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter15/">15. Barrier Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter16/">16. Duality Revisited</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter17/">17. Primal-Dual Interior-Point Methods</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter18/">18. Quasi-Newton Methods</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter19/">19. Proximal Netwon Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter20/">20. Dual Methods</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter21/">21. Alternating Direction Method of Mulipliers</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter22/">22. Conditional Gradient Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter23/">23. Coordinate Descent</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter24/">24.  Mixed Integer Programming 1</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/contents/chapter25/">25.  Mixed Integer Programming 2</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://simonseo.github.io/convex-optimization/convex-optimization/reference/">26. Reference</a>
        
      
    

    <span class="sidebar-nav-item">Currently v1.1.0</span>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2022. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap github-md-body">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/convex-optimization/" title="Home">모두를 위한 컨벡스 최적화</a>
            <small></small>
          </h3>
          <a class="github-logo__wrapper" target="_blank" href="https://github.com/convex-optimization-for-all/convex-optimization-for-all.github.io" titltle="Github">
           <svg class="github-logo" xmlns="http://www.w3.org/2000/svg"  viewBox="0 0 48 48"><linearGradient id="rL2wppHyxHVbobwndsT6Ca" x1="4" x2="44" y1="23.508" y2="23.508" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#4c4c4c"/><stop offset="1" stop-color="#343434"/></linearGradient><path fill="url(#rL2wppHyxHVbobwndsT6Ca)" d="M24,4C12.954,4,4,12.954,4,24c0,8.887,5.801,16.411,13.82,19.016h12.36	C38.199,40.411,44,32.887,44,24C44,12.954,35.046,4,24,4z"/><path d="M30.01,41.996L30,36.198c0-0.939-0.22-1.856-0.642-2.687c5.641-1.133,8.386-4.468,8.386-10.177	c0-2.255-0.665-4.246-1.976-5.92c0.1-0.317,0.174-0.645,0.22-0.981c0.188-1.369-0.023-2.264-0.193-2.984l-0.027-0.116	c-0.186-0.796-0.409-1.364-0.418-1.388l-0.111-0.282l-0.111-0.282l-0.302-0.032l-0.303-0.032c0,0-0.199-0.021-0.501-0.021	c-0.419,0-1.04,0.042-1.627,0.241l-0.196,0.066c-0.74,0.249-1.439,0.485-2.417,1.069c-0.286,0.171-0.599,0.366-0.934,0.584	C27.334,12.881,25.705,12.69,24,12.69c-1.722,0-3.365,0.192-4.889,0.571c-0.339-0.22-0.654-0.417-0.942-0.589	c-0.978-0.584-1.677-0.819-2.417-1.069l-0.196-0.066c-0.585-0.199-1.207-0.241-1.626-0.241c-0.302,0-0.501,0.021-0.501,0.021	l-0.302,0.032l-0.3,0.031l-0.112,0.281l-0.113,0.283c-0.01,0.026-0.233,0.594-0.419,1.391l-0.027,0.115	c-0.17,0.719-0.381,1.615-0.193,2.983c0.048,0.346,0.125,0.685,0.23,1.011c-1.285,1.666-1.936,3.646-1.936,5.89	c0,5.695,2.748,9.028,8.397,10.17c-0.194,0.388-0.345,0.798-0.452,1.224c-0.197,0.067-0.378,0.112-0.538,0.137	c-0.238,0.036-0.487,0.054-0.739,0.054c-0.686,0-1.225-0.134-1.435-0.259c-0.313-0.186-0.872-0.727-1.414-1.518	c-0.463-0.675-1.185-1.558-1.992-1.927c-0.698-0.319-1.437-0.502-2.029-0.502c-0.138,0-0.265,0.01-0.376,0.028	c-0.517,0.082-0.949,0.366-1.184,0.78c-0.203,0.357-0.235,0.773-0.088,1.141c0.219,0.548,0.851,0.985,1.343,1.255	c0.242,0.133,0.765,0.619,1.07,1.109c0.229,0.368,0.335,0.63,0.482,0.992c0.087,0.215,0.183,0.449,0.313,0.732	c0.47,1.022,1.937,1.924,2.103,2.023c0.806,0.483,2.161,0.638,3.157,0.683l0.123,0.003c0,0,0.001,0,0.001,0	c0.24,0,0.57-0.023,1.004-0.071v2.613c0.002,0.529-0.537,0.649-1.25,0.638l0.547,0.184C19.395,43.572,21.645,44,24,44	c2.355,0,4.605-0.428,6.703-1.176l0.703-0.262C30.695,42.538,30.016,42.422,30.01,41.996z" opacity=".05"/><path d="M30.781,42.797c-0.406,0.047-1.281-0.109-1.281-0.795v-5.804c0-1.094-0.328-2.151-0.936-3.052	c5.915-0.957,8.679-4.093,8.679-9.812c0-2.237-0.686-4.194-2.039-5.822c0.137-0.365,0.233-0.75,0.288-1.147	c0.175-1.276-0.016-2.086-0.184-2.801l-0.027-0.116c-0.178-0.761-0.388-1.297-0.397-1.319l-0.111-0.282l-0.303-0.032	c0,0-0.178-0.019-0.449-0.019c-0.381,0-0.944,0.037-1.466,0.215l-0.196,0.066c-0.714,0.241-1.389,0.468-2.321,1.024	c-0.332,0.198-0.702,0.431-1.101,0.694C27.404,13.394,25.745,13.19,24,13.19c-1.762,0-3.435,0.205-4.979,0.61	c-0.403-0.265-0.775-0.499-1.109-0.699c-0.932-0.556-1.607-0.784-2.321-1.024l-0.196-0.066c-0.521-0.177-1.085-0.215-1.466-0.215	c-0.271,0-0.449,0.019-0.449,0.019l-0.302,0.032l-0.113,0.283c-0.009,0.022-0.219,0.558-0.397,1.319l-0.027,0.116	c-0.169,0.715-0.36,1.524-0.184,2.8c0.056,0.407,0.156,0.801,0.298,1.174c-1.327,1.62-1.999,3.567-1.999,5.795	c0,5.703,2.766,8.838,8.686,9.806c-0.395,0.59-0.671,1.255-0.813,1.964c-0.33,0.13-0.629,0.216-0.891,0.256	c-0.263,0.04-0.537,0.06-0.814,0.06c-0.69,0-1.353-0.129-1.69-0.329c-0.44-0.261-1.057-0.914-1.572-1.665	c-0.35-0.51-1.047-1.417-1.788-1.755c-0.635-0.29-1.298-0.457-1.821-0.457c-0.11,0-0.21,0.008-0.298,0.022	c-0.366,0.058-0.668,0.252-0.828,0.534c-0.128,0.224-0.149,0.483-0.059,0.708c0.179,0.448,0.842,0.85,1.119,1.002	c0.335,0.184,0.919,0.744,1.254,1.284c0.251,0.404,0.37,0.697,0.521,1.067c0.085,0.209,0.178,0.437,0.304,0.712	c0.331,0.719,1.353,1.472,1.905,1.803c0.754,0.452,2.154,0.578,2.922,0.612l0.111,0.002c0.299,0,0.8-0.045,1.495-0.135v3.177	c0,0.779-0.991,0.81-1.234,0.81c-0.031,0,0.503,0.184,0.503,0.184C19.731,43.64,21.822,44,24,44c2.178,0,4.269-0.36,6.231-1.003	C30.231,42.997,30.812,42.793,30.781,42.797z" opacity=".07"/><path fill="#fff" d="M36.744,23.334c0-2.31-0.782-4.226-2.117-5.728c0.145-0.325,0.296-0.761,0.371-1.309	c0.172-1.25-0.031-2-0.203-2.734s-0.375-1.25-0.375-1.25s-0.922-0.094-1.703,0.172s-1.453,0.469-2.422,1.047	c-0.453,0.27-0.909,0.566-1.27,0.806C27.482,13.91,25.785,13.69,24,13.69c-1.801,0-3.513,0.221-5.067,0.652	c-0.362-0.241-0.821-0.539-1.277-0.811c-0.969-0.578-1.641-0.781-2.422-1.047s-1.703-0.172-1.703-0.172s-0.203,0.516-0.375,1.25	s-0.375,1.484-0.203,2.734c0.077,0.562,0.233,1.006,0.382,1.333c-1.31,1.493-2.078,3.397-2.078,5.704	c0,5.983,3.232,8.714,9.121,9.435c-0.687,0.726-1.148,1.656-1.303,2.691c-0.387,0.17-0.833,0.33-1.262,0.394	c-1.104,0.167-2.271,0-2.833-0.333s-1.229-1.083-1.729-1.813c-0.422-0.616-1.031-1.331-1.583-1.583	c-0.729-0.333-1.438-0.458-1.833-0.396c-0.396,0.063-0.583,0.354-0.5,0.563c0.083,0.208,0.479,0.521,0.896,0.75	c0.417,0.229,1.063,0.854,1.438,1.458c0.418,0.674,0.5,1.063,0.854,1.833c0.249,0.542,1.101,1.219,1.708,1.583	c0.521,0.313,1.562,0.491,2.688,0.542c0.389,0.018,1.308-0.096,2.083-0.206v3.75c0,0.639-0.585,1.125-1.191,1.013	C19.756,43.668,21.833,44,24,44c2.166,0,4.243-0.332,6.19-0.984C29.585,43.127,29,42.641,29,42.002v-5.804	c0-1.329-0.527-2.53-1.373-3.425C33.473,32.071,36.744,29.405,36.744,23.334z M11.239,32.727c-0.154-0.079-0.237-0.225-0.185-0.328	c0.052-0.103,0.22-0.122,0.374-0.043c0.154,0.079,0.237,0.225,0.185,0.328S11.393,32.806,11.239,32.727z M12.451,33.482	c-0.081,0.088-0.255,0.06-0.389-0.062s-0.177-0.293-0.096-0.381c0.081-0.088,0.255-0.06,0.389,0.062S12.532,33.394,12.451,33.482z M13.205,34.732c-0.102,0.072-0.275,0.005-0.386-0.15s-0.118-0.34-0.016-0.412s0.275-0.005,0.386,0.15	C13.299,34.475,13.307,34.66,13.205,34.732z M14.288,35.673c-0.069,0.112-0.265,0.117-0.437,0.012s-0.256-0.281-0.187-0.393	c0.069-0.112,0.265-0.117,0.437-0.012S14.357,35.561,14.288,35.673z M15.312,36.594c-0.213-0.026-0.371-0.159-0.353-0.297	c0.017-0.138,0.204-0.228,0.416-0.202c0.213,0.026,0.371,0.159,0.353,0.297C15.711,36.529,15.525,36.62,15.312,36.594z M16.963,36.833c-0.227-0.013-0.404-0.143-0.395-0.289c0.009-0.146,0.2-0.255,0.427-0.242c0.227,0.013,0.404,0.143,0.395,0.289	C17.381,36.738,17.19,36.846,16.963,36.833z M18.521,36.677c-0.242,0-0.438-0.126-0.438-0.281s0.196-0.281,0.438-0.281	c0.242,0,0.438,0.126,0.438,0.281S18.762,36.677,18.521,36.677z"/></svg>
          </a>
        </div>
      </div>

      <div class="container content">
        <h1>14. Newton's Method</h1>






<!-- Get first post and show it -->

<p>이 장에서는 Newton’s Method에 대해 살펴본다.</p>

<p>Newton’s method는 두 번 미분가능한 함수에 대하여 second-order Taylor expansion으로 함수를 근사한 뒤, 근사 함수의 최솟값을 찾으며 해에 접근하는 방법이다. 해의 근처에서는 quadratic convergence를 만족하며, gradient descent에 비하여 무척 빠른 수렴속도를 보인다.</p>

<h2 id="references-and-further-readings">References and further readings</h2>
<ul>
  <li>S. Boyd and L. Vandenberghe (2004), “Convex optimization”, Chapter 9 and 10</li>
  <li>Y. Nesterov (1998), “Introductory lectures on convex optimization: a basic course”, Chapter 2</li>
  <li>Y. Nesterov and A. Nemirovskii (1994), “Interior-point polynomial methods in convex programming”, Chapter 2</li>
  <li>J. Nocedal and S. Wright (2006), “Numerical optimization”, Chapters 6 and 7</li>
  <li>L. Vandenberghe, Lecture notes for EE 236C, UCLA, Spring 2011-2012</li>
</ul>


<!-- Remove first element from post_list which is already shown above. -->
  

<!-- List up the posts in the chapter -->
<ul style="list-style: none;">

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_1">14-01 Newton's method</a>
    </li>
  
  

  
  
  
  
  
    <li style="text-align:left; vertical-align: middle;  margin-left: 0em;" >
      <a href="#_page_2"> 14-01-01 Newton's method interpretation</a>
    </li>
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_3">14-02 Interpretation & Properties</a>
    </li>
  
  

  
  
  
  
  
    <li style="text-align:left; vertical-align: middle;  margin-left: 0em;" >
      <a href="#_page_4"> 14-02-01 Root finding</a>
    </li>
  

  
  
  
  
  
    <li style="text-align:left; vertical-align: middle;  margin-left: 0em;" >
      <a href="#_page_5"> 14-02-02 Affine invariance of Newton's method</a>
    </li>
  

  
  
  
  
  
    <li style="text-align:left; vertical-align: middle;  margin-left: 0em;" >
      <a href="#_page_6"> 14-02-03 Local convergence analyisis</a>
    </li>
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_7">14-03 Newton decrement</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_8">14-04 Backtracking line search</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_9">14-05 Convergence analysis</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_10">14-06 Self concordance</a>
    </li>
  
  

  
  
  
  
  
    <li style="text-align:left; vertical-align: middle;  margin-left: 0em;" >
      <a href="#_page_11"> 14-06-01 Definition of self-concordant functions</a>
    </li>
  

  
  
  
  
  
    <li style="text-align:left; vertical-align: middle;  margin-left: 0em;" >
      <a href="#_page_12"> 14-06-02 Convergence analysis for self-concordant functions</a>
    </li>
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_13">14-07 Comparison to first-order method</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_14">14-08 Special cases</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_15">14-09 Quasi-Newton methods</a>
    </li>
  
  

</ul>


<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_1"></a>14-01 Newton's method</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
});
</script>

<p>제약조건이 없고(unconstrained), 두 번 미분 가능하고 convex이며, dom(\(f\)) = \(\mathbb{R}^{n}\)인 함수 \(f\)에 대한 최적화 문제를 살펴보자.</p>

<blockquote>
\[\begin{align}
\min_{x} f(x)
\end{align}\]
</blockquote>

<p><a href="/convex-optimization/contents/chapter06/2021/03/20/06_00_gradient_descent/">Gradient descent</a>에서는 이 함수 \(f\)에 대해 아래와 같은 과정을 수행하였다.</p>

<ol>
  <li>2차 테일러 근사를 수행</li>
  <li>2차 미분 항에 해당하는 Hessian matrix를 \(I/t\), 즉 정방행렬에 t(step size)를 나눈 값으로 가정</li>
  <li>Quadratic approximation을 수행하여 update step를 진행</li>
</ol>

<p>자세한 과정은 다음 페이지의 gradient descent update step에서 설명한다. 이 때의 매 update step 식은 다음과 같다.</p>

<blockquote>
\[\begin{align}
&amp;\text{choose initial } x^{(0)} \in \mathbb{R}^{n},\\\\
&amp;x^{(k)} = x^{(k-1)} - t_{k} \cdot \nabla f(x^{(k-1)}), \qquad k = 1,2,3,...
\end{align}\]
</blockquote>

<p>Newton’s method(pure Newton’s method)는 기존 gradient descent에서 \(\frac{1}{t}I\)로 가정했던 2차 미분항을 실제로 계산하여 quadratic approximation을 수행하고, update step 를 진행한다. 이 과정 또한 다음 페이지의 Newton’s method update step에서 설명한다. 이 때의 매 update step 식은 다음과 같다.</p>

<blockquote>
\[\begin{align}
&amp;\text{choose initial } x^{(0)} \in \mathbb{R}^{n},\\\\
&amp;x^{(k)} = x^{(k-1)} - \Big(\nabla^{2}f(x^{(k-1)})\Big)^{-1} \nabla f(x^{(k-1)}), \qquad k = 1,2,3,...
\end{align}\]
</blockquote>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_2"></a>14-01-01 Newton's method interpretation</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
});
</script>

<p>이 페이지에서는 앞서 다루었던 update step이 원 함수 \(f\)의 quadratic approximation으로부터 어떻게 유도되는지 살펴본다. 또한 <a href="/convex-optimization/contents/chapter06/2021/03/20/06_00_gradient_descent/">6장</a>에서 다룬 gradient descent의 update step와 비교해본다.</p>

<h2 id="newtons-method-update-step">Newton’s method update step</h2>
<p>함수 \(f\)의 2차 테일러 근사(quadratic approximation)은 다음과 같다.</p>

<blockquote>
\[\begin{align}
f(y)	\approx f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2}(y-x)^{T}\nabla^{2}f(x)(y-x),\\\\
f_{approx}(y)	= f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2}(y-x)^{T}\nabla^{2}f(x)(y-x).
\end{align}\]
</blockquote>

<p>여기서 \(y\)는 다음 스텝의 \(x\) 값인 \(x^{+}\)이다. 또한 quadratic approximation을 \(f_{approx}\)로 정한다.</p>

<p>우리는 이 \(f_{approx}\) 즉, quadratic approximation을 최소로 만드는 입력 \(y\)를 찾으려 한다. 이때 \(f_{approx}\)는 convex이므로 위 식의 gradient를 0로 만드는 입력 \(y\)가 \(f_{approx}\)를 최소로 만들 것이다. 이 결과가 Newton’s method에서의 step update 식이 된다. 아래 식의 미분은 y에 대한 미분 임을 기억하자.</p>

<blockquote>
\[\begin{align}
\nabla f_{approx}(y)	&amp;= \nabla f(x) +\frac{1}{2} \Big((\nabla^{2} f(x))^{T}(y-x)+(y-x)^{T}\nabla^{2}f(x)\Big)\\\\
&amp;=\nabla f(x) +\nabla^{2} f(x)(y-x)\\\\
&amp; = 0,\\\\
\Leftrightarrow y &amp;= x-(\nabla^{2}f(x))^{-1}\nabla f(x).
\end{align}\]
</blockquote>

<h2 id="gradient-descent-update-step">Gradient descent update step</h2>
<p>gradient descent에서는 함수 \(f\)의 2차 테일러 근사 항을 사용하고, 2차 항의 경우 실제 2차 미분 결과가 아닌, 정방행렬(identity matrix)과 이를 \(t\)로 나눈 값으로 가정한다.</p>

<blockquote>
\[\begin{align}
f(y)	\approx f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2t}\|{y-x}\|_{2}^{2},\\\\
f_{approx}(y)	= f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2t}\|{y-x}\|_{2}^{2}.\\\\
\end{align}\]
</blockquote>

<p>Newton’s method와 동일하게 위 근사식의 gradient가 0인 \(y\)값, 즉 \(x^{+}\)를 정할 수 있다.</p>
<blockquote>
\[\begin{align}
\nabla f(y) &amp;= \nabla f(x) + \frac{1}{t}(y-x), \\\\
&amp;= 0,\\\\
y &amp;= x-t\nabla f(x).
\end{align}\]
</blockquote>

<p>이 결과는 gradient descent의 step update와 동일하다.</p>

<p>gradient descent의 자세한 내용은 <a href="/convex-optimization/contents/chapter06/2021/03/20/06_00_gradient_descent/">gradient descent 장</a>에서 참고할 수 있다.</p>

<h2 id="example">Example</h2>
<p>예시로써, 함수 \(f = (10x_{1}^{2}+x_{2}^{2})/2+5log(1+e^{-x_{1}-x_{2}})\)에 대하여 거의 동등한 길이의 step을 진행한다고 가정하고, 즉 newton’s method의 업데이트 크기만큼 매번 gradient descent에서의 step size를 정하고, gradient descent(검정)와 Newton’s method(파랑)의 step에 따른 수렴 방향을 비교해본다.</p>

<figure class="image" style="align: center;">
<p align="center">
 <img src="/convex-optimization/img/chapter_img/chapter14/gd.jpeg" alt="" width="70%" height="70%" />
 <figcaption style="text-align: center;">[Fig 1] Comparison between gradient descent(black) and Newton's method(blue)[3]</figcaption>
</p>
</figure>

<p>Fig 1에서도 알 수 있다시피, gradient descent는 2차 미분 항을 정방행렬에 상수가 곱해진 값으로 가정하고 gradient를 계산하기 때문에, 등고선(contour)의 접선 방향에 수직하게(perpendicular) 수렴함을 확인할 수 있고, Newton’s method에 비해 느린 수렴 속도를 보인다. 이 후의 나머지 장에서는 Newton’s method의 성질과 특징, 수렴성, 예시 등을 다룬다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_3"></a>14-02 Interpretation & Properties</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
});
</script>

<p>이 장에서는 Newton’s method의 성질에 앞서 목적함수의 근을 찾는(root finding) 문제에 Newton’s method를 적용해보는 방법에 대하여 알아본다.</p>

<p>후에, Newton’s method의 두 가지 중요한 성질인 Affine invariance와 Local convergence에 대해서 살펴보고자 한다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_4"></a>14-02-01 Root finding</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
});
</script>

<p>이 장에서는 root finding 문제에 Newton’s method를 적용해본다. 우리가 논하는 최적화 문제에서의 Newton’s method와 약간의 차이가 있으므로 이를 설명한다.[<a href="https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization">최적화 문제에서의 Newton’s method</a>][<a href="https://en.wikipedia.org/wiki/Newton%27s_method">root finding에서의 newton’s method</a>]</p>

<h2 id="newtons-method-for-root-finding">Newton’s method for root finding</h2>
<p>\(F:\mathbb{R}^{n}\rightarrow \mathbb{R}^{n}\)인 벡터 함수(vector function)가 있다고 하자. 또한, 이 함수의 근, 즉 함수값을 0으로 만드는 \(x\)값을 찾는 문제(root-finding)를 생각해보자.</p>

<blockquote>
\[\begin{align}
F(x) = 0.
\end{align}\]
</blockquote>

<p>이 문제는 초기값 \(x^{(0)}\)를 정한 뒤, 반복적으로 Newton’s method를 적용하여 해에 접근해갈 수 있다.</p>

<blockquote>
\[\begin{align}
&amp;\text{choose initial }x^{(0)}\in \mathbb{R}^{n},\\\\
&amp;x^{(k)}=x^{(k-1)}-\nabla F(x^{(k-1)})^{-1}F(x^{(k-1)}), \qquad k=1,2,3,...\\\\
\end{align}\]
</blockquote>

<p>여기서 \(\nabla F(x^{(k-1)})\)은 \(x^{(k-1)}\)일때의 \(F\)의 Jacobian 행렬이다. Newton step인 \(x^{+}=x-\nabla F(x)^{-1}F(x)\)는 아래와 같이 F를 선형근사(linear approximation)함으로써 계산할 수 있다.</p>

<blockquote>
\[\begin{align}
F(y)\approx F(x) + F^{'}(x)(y-x) = 0\\\\
y = x^{+}=x-F^{'}(x)^{-1}F(x).
\end{align}\]
</blockquote>

<h2 id="newtons-method-for-optimization-problem">Newton’s method for optimization problem</h2>
<p>Newton’s method를 아래와 같은 최적화 문제에 적용한다고 보면,</p>

<blockquote>
\[\begin{align}
\min_{x} F(x)
\end{align}\]
</blockquote>

<p>이는 목적함수 \(F(x)\)의 gradient, \(\nabla{F(x)}=0\), 즉 \(\nabla F(x)\)의 root finding 문제에 Newton’s method를 적용하는 것과 동일하다.</p>

<p>정리하면, 최적화 문제에서 주어진 함수 도함수의 근(\(\nabla F=0\))을 Newton’s method를 이용해서 찾는 것과 달리, 근을 찾는 문제는 함수 값 자체의 근(\(F=0\))을 Newton’s method를 이용해서 찾아야 하므로 각 문제에 대하여 Newton’s method의 x에 대한 update 식에서 미분항에 한 차수 차이가 발생한다.</p>

<h2 id="root-finding-example">Root finding example</h2>
<p>\(F:\mathbb{R}\rightarrow\mathbb{R}\)이 다음과 같이 정의된다고 하자.</p>

<blockquote>
\[\begin{align}
F(x)=x^{2}-2
\end{align}\]
</blockquote>

<p>\(x^{(0)}=1\)으로 정하고, pure Newton’s method를 적용하면 다음과 같다.</p>

<figure class="image" style="align: center;">
<p align="center">
 <img src="/convex-optimization/img/chapter_img/chapter14/table1.jpeg" alt="" width="90%" />
 <figcaption style="text-align: center;">[Fig 1] Newton's method applied on example[3]</figcaption>
</p>
</figure>

<p>k(iteration 횟수)가 증가함에 따라 \(x\)가 근인 \(\sqrt 2\)에 가까워짐을 확인할 수 있다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_5"></a>14-02-02 Affine invariance of Newton's method</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
});
</script>

<p>Newton’s method의 중요한 성질 중 하나는 affine invariance하다는 것이다. 이는 update의 방향이 좌표계의 affine한 변환에 대하여 독립적이라는 의미이다. 예를 들어, gradient descent의 경우 affine 변환에 variant 하기 때문에, 좌표계 공간에 따라 수렴 속도가 다르다.</p>

<p>이 페이지에서는 affine invariance를 유도해본다.</p>

<h2 id="affine-invariance--proof">Affine invariance : proof</h2>
<p>\(f:\mathbb{R}^{n}\rightarrow \mathbb{R}\)이 두 번 미분 가능하고, \(A\in \mathbb{R}^{n\times n}\)은 nonsingular하다고 하자. 또한 \(g(y)\)를 \(f(Ay)\)로 정의하자. \(g(y):=f(Ay)\). 이는 \(y\)를 입력으로 받는 어떤 함수 \(g\)와, \(y\)에 대해서 \(A\)로 affine transformation된 \(Ay\)를 입력으로 받는 함수 \(f\)의 출력값이 같음을 의미한다. Notation과 gradient의 인자에 대한 혼선을 줄이고자, \(x:=Ay\)로 정의한다.</p>

<p>Chain rule을 활용하여 양변을 미분, 두 번 미분한 결과를 정리하면 다음과 같다.</p>

<blockquote>
\[\begin{align}
\nabla g(y) &amp;= A^{T} \nabla f(x)\\\\
\nabla^{2} g(y) &amp;= A^{T}\nabla^{2}f(x)A,
\end{align}\]
</blockquote>

<p>\(y\)에 대한 \(g\)의 Newton step은 다음과 같다.</p>

<blockquote>
\[\begin{align}
y^{+}  = y-(\nabla^{2}g(y))^{-1}\nabla g(y).
\end{align}\]
</blockquote>

<p>여기서 함수 \(g\) 대신에, \(x\)에 대한 함수 \(f\)로 변환하고 정리하면, \(x\)와 \(f\)에 대한 Newton step을 유도할 수 있다.</p>

<blockquote>
\[\begin{align}
y^{+} &amp;= y-(A^{T}\nabla^{2}f(x)A)^{-1}A^{T} \nabla f(x)\\\\
\Leftrightarrow y^{+} &amp;= y-A^{-1}(\nabla^{2}f(x))^{-1}(A^{T})^{-1}A^{T} \nabla f(x)\\\\
\Leftrightarrow Ay^{+} &amp;= Ay-(\nabla^{2}f(x))^{-1}\nabla f(x)\\\\
\Leftrightarrow x^{+} &amp;= x - \nabla^{2}f(x)^{-1}\nabla f(x).
\end{align}\]
</blockquote>

<p>이는 Newton step이 non singular한 matrix로 표현되는 affine transformation에 대하여 좌표변환된 좌표계에서의 update가 서로 같다는 것, 즉 affine invariant함을 의미한다.</p>

<p>동일한 방법으로 gradient descent의 affine invariacne를 확인해보고자 step update에 대하여 유도해보면, 다음과 같은 결과를 얻을 수 있다.</p>

<blockquote>
\[\begin{align}
y^{+} &amp;= y-t_{k}\cdot \nabla g(y)\\\\
\Leftrightarrow y^{+} &amp;= y-t_{k}\cdot \nabla f(x)A^{T}\\\\
\Leftrightarrow x^{+} &amp;= x - t_{k}\cdot A\nabla f(x)A^{T}. 
\end{align}\]
</blockquote>

<p>Gradient descent의 경우 Hessian matrix를 \(\frac{1}{t}I\)로 근사하여 업데이트하기 때문에, affine transformation된 coordinate에 대하여 update의 방향이 달라짐을 알 수 있다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_6"></a>14-02-03 Local convergence analyisis</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
});
</script>

<p>Newton’s method의 두 번째 중요한 성질로는 특정 조건들을 만족하면, 해의 근처에서 수렴성이 보장된다는 것이다. 이를 local convergence라고 명명한다.  <a href="/convex-optimization/contents/chapter14/2021/03/26/14_01_newton_method/">14-01</a>에서부터 우리가 논해온 pure Newton’s method의 경우 수렴성이 보장되지 않기 때문에, 후에 이전에 <a href="/convex-optimization/contents/chapter06/2021/03/20/06_00_gradient_descent/">6장</a>에서 다루었던 backtracking line search를 동일하게 적용하여 step size를 조절하여 수렴성을 보장하는 damped Newton’s method를 고안하고, 이에 대한 수렴성을 분석한다.</p>

<blockquote>
  <p>정리 : \(F : \mathbb{R}^{n}\, \rightarrow  \, \mathbb{R}^{n}\) 가 연속으로 미분가능(continuosly differentiable)하고,  \(x^{\star} \in \mathbb{R}^{n}\) 가 함수 \(F\)의 근이라고 하자, 즉, \(F(x^{\star})=0\)이다.
이때  \(F^{'}(x^{\star})\)이 non-singular 하다면 아래의 (a), (b)를 만족한다. <br />
(a) 만약 \(\| x^{(0)}-x^{\star} \|&lt;\delta\)를 만족하는 양수의 \(\delta\)(&gt;0)가 존재하고, Newton’s method가 정의되어 있으면 밑의 식(converges superlinearly)을 만족한다.
\begin{align}
\lim_{ k \rightarrow \infty } \frac{ || x^{ (k+1) }-x^{ \star } || } { || x^{ (k) }-x^{ \star } || } =0.
\end{align} <br />
(b) 만약 \(F^{'}\)가 \(x^{\star}\)의 근처에서 Lipshitz continuous하면, 밑의 식(quadratic convergence)을 만족하는 양수 K(&gt;0)가 존재한다.
\begin{align}
||x^{ (k+1) } - x^{ \star }|| \leq K || x^{ (k) }-x^{ \star }||^{2}.
\end{align}</p>
</blockquote>

<h2 id="proof-of-a">Proof of (a)</h2>
<blockquote>
  <p>Taylor expansion으로 \(F(x^{\star})\)를 1st order까지 정리한다. 2nd order 이상의 항은 1st order의 norm의 상수배에 bound 되므로, little-o notation을 사용하여 다음과 같이 나타낼 수 있다.
\begin{align}
0=F(x^{\star}) = F(x^{k}) +\nabla F(x^{k})(x^{\star}-x^{k})+o(||x^{k}-x^{\star}||).<br />
\end{align}
양변에 \(\nabla F(x^{k})^{-1}\)를 곱하고 정리한다. little-o의 경우 상수항 취급되므로 이를 무시할 수 있다.
\begin{align}
x^{k}-x^{\star}-\nabla F(x^{k})^{-1} F(x^{k}) = o(||x^{k}-x^{\star}||).
\end{align}
Newton’s method \(x^{k+1}=x^{k}-\nabla F(x^{k})^{-1}F(x^{k})\)를 이용하여 아래와 같은 결과를 얻을 수 있다.
\begin{align}
x^{k+1}-x^{\star}=o(||x^{k}-x^{\star}||),
\end{align}
따라서, \(x^{k} \neq x^{\star}\) 일 때, little-o의 limit-definition[<a href="https://en.wikipedia.org/wiki/Big_O_notation">wikipedia</a>]를 이용하여 (a)를 보일 수 있다.</p>
</blockquote>

<blockquote>
  <p>\begin{align}
\lim_{k\rightarrow \infty} \frac{||x^{k+1}-x^{\star}||}{||x^{k}-x^{\star}||} = \lim_{k\rightarrow \infty}\frac{o(||x^{k}-x^{\star}||)}{||x^{k}-x^{\star}||}.
\end{align}</p>
</blockquote>

<h2 id="proof-of-b">Proof of (b)</h2>
<p>과정이 [<a href="/convex-optimization/contents/chapter14/2021/03/26/14_05_convergence_analysis/">14-05</a>]의 Damped phase에서의 수렴 속도가 quadratic함을 증명하는 과정과 동일하다. 따라서 생략한다.</p>

<h2 id="example--divergence-case">Example : divergence case</h2>
<p>pure Netwon’s method로 수렴이 보장되지 않는 예시를 간략하게 살펴본다.</p>

<figure class="image" style="align: center;">
<p align="center">
 <img src="/convex-optimization/img/chapter_img/chapter14/1_.png" alt="" width="70%" height="70%" />
 <figcaption style="text-align: center;">[Fig 1] pure Newton's method applied on root finding : divergence case </figcaption>
</p>
</figure>

<p><a href="https://slideplayer.com/slide/4998677/">image-link</a></p>

<p>그림에서와 같이 initial point \(x_0\)에 따라서, 해가 발산할 수 있음이 확인된다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_7"></a>14-03 Newton decrement</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
});
</script>

<p>이 장에서는 Newton decrement를 정의하고, 이 값의 의미를 살펴본다.</p>

<p>최적화 문제를 아래와 같이 정의할때, \(x\)에서의 Newton decrement를 \(\lambda(x)\)로 정의한다.</p>

<blockquote>
  <p>\begin{align}
\min_{x} \quad f(x),\<br />
\end{align}
\begin{align}
\lambda(x) = (\nabla f(x)^{T}(\nabla^{2}f(x))^{-1}\nabla f(x))^{1/2}.
\end{align}</p>
</blockquote>

<h2 id="characteristics-of-newton-decrement">Characteristics of Newton decrement</h2>
<p>첫번째로, Newton decrement는 함수 \(f(x)\)와 이 함수의 이차 근사(quadratic approximation)의 최소값의 차이와 관계가 있다.
이 차이를 구해보면 다음과 같다.</p>
<blockquote>
\[\begin{align}
f(x)-&amp;\min_{y} \big( f(x)+\nabla f(x)^{T}(y-x)+\frac{1}{2}(y-x)^{T}\nabla^{2}f(x)(y-x)\big),\\\\
f(x)-&amp;\bigg( f(x) + \nabla^{T}f(x)\big( -(\nabla^{2} f(x) )^{-1} \nabla f(x)\big) + \frac{1}{2}\big( -(\nabla^{2}f(x))^{-1} \nabla f(x) \big)^{T} \nabla ^{2}f(x) \big( -(\nabla^{2}f(x))^{-1}\nabla f(x) \big) \bigg) \\\\ 
&amp;= \frac{1}{2}\nabla f(x)^{T}(\nabla^{2} f(x) )^{-1}\nabla f(x) = \frac{1}{2}\lambda(x)^{2}.
\end{align}\]
</blockquote>

<p>즉, 우리는 \(\frac{1}{2}\lambda^{2}(x)\)를 suboptimality gap인 \(f(x)-f^{\star}\)의 approximate bound로 생각할 수 있다.</p>

<p>두 번째로는 Newton direction을 Newton method에서 매 iteration의 update 방향 \(v = -(\nabla^{2}f(x))^{-1}\nabla f(x)\)라고 할 때, Newton decrement는 \(f(x)\)의 hessian인 \(\nabla^{2}f(x)\)로 정의된 norm에서의 Newton step의 길이라고 볼 수 있다.</p>

<p>또는 달리 말해서, 이를 일종의 mahalanobis distance[<a href="https://en.wikipedia.org/wiki/Mahalanobis_distance">Wikipedia</a>]로 볼 수 있는데, 즉 새롭게 이동할 step \(y\)를 observation이라하고, 현재의 위치 \(x\)를 mean, \(f(x)\)의 hessian을 covariance로 보는 관점이다.</p>

<p>Mahalanobis distance가 어떤 point와, 분포의 평균과의 거리를 해당 방향의 표준편차의 크기로 나눈 결과라는 정의로 생각하면, 현재의 위치를 mean으로 가지고 hessian을 covariance로 가지는 distribution에 대하여, 새로운 step의 point에 대한 distance를 구한 것이다.</p>

<p>P-quadratic norm([1]의 A1.3)의 형태를 가지는 이 식을 정리하면 다음과 같다.</p>

<blockquote>
  <p>\begin{align}
\lambda(x) = (v^{T}\nabla^{2} f(x)v)^{1/2} = ||v||_{\nabla^{2}f(x)}
\end{align}</p>
</blockquote>

<p>세번째로 Newton’s method의 step update의 크기 \(\Delta x_{nt}\)로 Newtond decrement를 나타낼 수 있다.</p>
<blockquote>
  <p>\begin{align}
x^{+} &amp;= x-\big(\nabla^{2} f(x) \big)^{-1} \nabla f(x) &amp;\ 
\end{align}
\begin{align}
\Delta x_{nt} &amp;= -\big(\nabla^{2} f(x) \big)^{-1} \nabla f(x) &amp;<br />
\end{align}
\begin{align}
\nabla f(x)^{T} \Delta x_{nt} &amp;= -\lambda (x)^{2}
\end{align}</p>
</blockquote>

<p>이 식의 중간과정을 활용하면 Newton decrement를 증분과 Hessian에 관한 식으로도 표현할 수 있다.</p>
<blockquote>
  <p>\begin{align}
\lambda(x) = (\Delta x_{nt}^{T}\nabla^{2} f(x) \Delta x_{nt})^{1/2}.
\end{align}</p>
</blockquote>

<p>마지막으로, Newton decrement 또한, Newton step와 동일하게 affine invariant하다. 다시 말해, 어떤 nonsingular matrix에 대하여 \(g(y) = f(Ay)\)이 함수가 정의되어있다면, \(x = Ay\)에서 \(\lambda_{g(y)} = \lambda_{f(x)}\)이다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_8"></a>14-04 Backtracking line search</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
});
</script>

<p>지금까지 우리는 pure Newton’s method에 대해 살펴보았다. 하지만. 이 방법은 수렴이 보장되지 않으므로 backtracking line search를 활용하여 수렴을 보장하는 damped Newton’s method에 대해 살펴본다.</p>

<h2 id="damped-newtons-method">Damped Newton’s method</h2>
<p>기존의 pure Newton’s method는 다음과 같은 update식을 반복하였다. (여기서 \(t=1\)이다.)</p>

<blockquote>
  <p>\begin{align}
x^{+} = x -t(\nabla^{2}f(x))^{-1}\nabla f(x).
\end{align}</p>
</blockquote>

<p>Damped Newton’s method는 이전의 backtracking line search와 동일하게, update 과정에서 발산할 가능성이 있는 경우, 즉 update된 위치에서의 원함수 \(f\)의 값이 근사 함수의 값보다 크게되면 발산할 가능성이 존재하므로, step size \(t\)를 줄이는 과정을 거친다.</p>

<p>따라서 다음과 같은 과정을 추가하여 \(t\)의 update 여부를 결정한다.</p>
<blockquote>
\[\begin{align}
&amp;\text{with parameters }0&lt;\alpha \leq \frac{1}{2}, 0&lt;\beta&lt;1, \\
&amp;\text{while } f(x+tv)&gt;f(x)+\alpha t \nabla f(x)^{T}v\\
&amp;\text{shrink }t=\beta t
\end{align}\]
</blockquote>

<p>여기서 \(v=-(\nabla^{2}f(x))^{-1}\nabla f(x)\)이고, \(\nabla f(x)^{T}v = -\lambda^{2}(x)\) 이다.</p>

<h2 id="example--logistic-regression">Example : logistic regression</h2>
<p>예제로, n = 500, p = 100인 logistic regression에 대해 각각 backtracking을 적용한 gradient descent와 newton’s method의 iteration에 따른 수렴속도를 비교해본다.</p>

<figure class="image" style="align: center;">
<p align="center">
 <img src="/convex-optimization/img/chapter_img/chapter14/2.jpeg" alt="" width="70%" height="70%" />
 <figcaption style="text-align: center;">[Fig 1] Logistic regression [3]</figcaption>
</p>
</figure>

<p>Newton’s method는 gradient descent보다 훨씬 더 빠른 수렴속도를 보인다. 다음 장에서 부터는 이 수렴속도에 대하여 살펴본다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_9"></a>14-05 Convergence analysis</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
    });
</script>

<p>지금까지 우리는 local convergence 성질 만을 가지는 pure Newton’s method와 여기에 backtracking line search를 적용하여, convex일때 global convergence를 보장하는 damped Newton’s method(Newton’s method with backtracking line search)에 대하여 살펴보았다.</p>

<p>이 장에서는 damped Newton’s method의 수렴속도를 분석(convergence anaylsis)하고자 한다. damped Newton’s method의 경우 backtracking이 적용되는 phase(damped phase : slow progress), bactracking이 더 이상 필요없는 local convergence한 phase(pure phase : quadratic convergence)로 나뉘어 convergence bound를 살펴보게 된다.</p>

<h2 id="conditions-of-f-for-convergence-analysis">Conditions of \(f\) for convergence analysis</h2>
<p>\(f\)는 convex이고, 두 번 미분 가능하며, \(dom(f)=\mathbb{R}^{n}\)을 가지고, 다음 세가지 조건을 만족한다고 가정하자.</p>

<ol>
  <li>\(\nabla f\)는 parameter L에 대하여 Lipschitz continuous이다.
    <blockquote>
\[\begin{align}
\|\nabla f(x) - \nabla f(y)\|_{2} \leq L\|x-y\|_{2} \quad \forall x,y.
\end{align}\]
    </blockquote>
  </li>
  <li>\(f\)는 parameter m에 대하여 strongly convex하다. (upper bound \(L\)과 Lipschitz continuous의 관계 : <a href="https://xingyuzhou.org/blog/notes/strong-convexity">출처</a>, <a href="/convex-optimization/contents/chapter06/2021/03/20/06_03_05_look_at_the_conditions_and_practicalities/">본서 : 06-03-05</a>)
    <blockquote>
\[\begin{align}
mI\preceq\nabla^{2}f(x)\preceq LI.
\end{align}\]
    </blockquote>
  </li>
  <li>\(\nabla^{2} f\)는 parameter M에 대하여 Lipschitz continuous하다.
    <blockquote>
\[\begin{align}
\|\nabla^{2}f(x)-\nabla^{2}f(y)\|_{2} \leq M\|x-y\|_{2} \quad \forall x,y.
\end{align}\]
    </blockquote>
  </li>
</ol>

<h2 id="convergence-analysis">Convergence analysis</h2>
<p>위 세가지 조건을 만족하면, \(0&lt;\eta \leq m^{2}/M\)와 \(\gamma&gt;0\)을 만족하는 \(\eta, \gamma\)에 대하여 각각의 phase에 대한 convergence를 아래와 같이 구할 수 있다.</p>

<blockquote>
  <p>Phase I : “Damped” phase, \(\|\nabla f(x^{(k)})\|_{2} \geq \eta\),</p>

\[\begin{align}
f(x^{(k+1)})-f(x^{(k)}) \leq -\gamma
\end{align}\]

  <p>Phase 2 : “Pure” phase, \(\|\nabla f(x^{(k)})\|_{2}&lt;\eta\), bactracking selects \(t = 1\)</p>

\[\begin{align}
\frac{M}{2m^{2}}\|\nabla f(x^{(k+1)})\|_{2} \leq \bigg( \frac{M}{2m^{2}}\|\nabla f(x^{(k)})\|_{2} \bigg)^{2}.
\end{align}\]
</blockquote>

<p>처음의 \(k\)번째 iteration에서 \(\|\nabla f(x^{(k)})\|_{2}&lt;\eta\)를 만족하여 Pure phase에 도달하게 되면, 이 후의 iteration에 대해서는 항상 이 조건을 만족함을 유념하자.</p>

<h2 id="convergence-analysis--written-in-optimal-value-term">Convergence analysis : written in optimal value term</h2>
<p>이제 각각의 phase의 convergence를 optimal value와의 차이로 비교해보고자 한다.</p>

<p>Phase1에서의 경우, \(x^{(0)}\)에서부터 k번의 iteration을 진행했다고 하면, 매 스텝마다의 식을 정리하여 다음과 같이 나타낼 수 있다.</p>

<blockquote>
\[\begin{align}
\require{cancel}
&amp; &amp;\cancel{f(x^{(1)})}-f(x^{(0)}) \leq -\gamma \\\\
&amp; &amp;\cancel{f(x^{(2)})}-\cancel{f(x^{(1)})} \leq -\gamma \\\\
&amp; &amp;\vdots \\\\
&amp;+ &amp;f(x^{(k)})-\cancel{f(x^{(k-1)})} \leq -\gamma \\\\
&amp;= &amp;f(x^{(k)})-f(x^{(0)})\leq -k\gamma.
\end{align}\]
</blockquote>

<p>양변에 \(f^{\star}\)를 빼주면 다음과 같은 결과를 얻을 수 있다. \(\nabla f(x^{(k+1)})\|&lt;\eta\)를 처음 만족하는 \(k\)를 \(k_{0}\)라 하자.</p>
<blockquote>
\[\begin{align}
f(x^{(k)})-f^{\star} \geq (f(x^{(0)})-f^{\star})-\gamma k \qquad \text{if }k \geq k_{0}
\end{align}\]
</blockquote>

<p>Phase 2에서는 \(k_{0}\)에서 iteration을 시작하여, step을 \(k-k_{0}\)번 진행했다고 가정한다. 또한 앞에서 \(\|\nabla f(x^{(k)})\|_2&lt;\eta \leq m^{2}/M\), 그리고 strong convexity를 활용하여 식을 정리할 수 있다.</p>
<blockquote>
\[\begin{align}
&amp; &amp;\frac{M}{2m^{2}}\|\nabla f^{(k_{0}+1)}\|_{2} \leq \big( \frac{M}{2m^{2}}\|\nabla f^{(k_{0})}\|_{2} \big) ^{2}.\\\\
&amp;\Leftrightarrow &amp;\frac{M}{2m^{2}}\|\nabla f^{(k_{0}+(k-k_{0}))}\|_{2} \leq \bigg( \big( \frac{M}{2m^{2}}\|\nabla f^{(k_{0}+1)}\|_{2} \big) ^{2} \bigg)^{k-k_{0}} \leq (\frac{1}{2})^{2^{(k-k_{0})}}.\\\\
&amp;\Leftrightarrow &amp;f(y)\geq f(x)+\nabla f(x)^{T}(y-x)+\frac{m}{2}\|y-x\|^{2}_{2}\geq f(x)-\frac{1}{2m}\|\nabla f(x)\|^{2}_{2}, \text{ for all }y,\\\\
&amp;\Leftrightarrow &amp;f(x^{(k)})-f^{\star} \leq \frac{1}{2m}\|\nabla f(x^{k})\|_{2}^{2}\leq \frac{2m^{3}}{M^{2}}(\frac{1}{2})^{2^{k-k_{0}+1}}.
\end{align}\]
</blockquote>

<p>따라서 \(k_{0}\)번째를 분기로 step에 따른 convergence를 아래와 같이 정리할 수 있다.</p>

<blockquote>
  <p>Theorem : backtracking line search를 사용하는 Netwon’s method는 두 단계의 convergence bounds를 가진다.
\(\begin{align}
&amp;f(x^{(k)})-f^{\star} \leq \begin{cases} (f(x^{(0)})-f^{\star})-\gamma k \qquad &amp;\text{if }k\leq k_{0}\\
\frac{2m^{3}}{M^{2}}(\frac{1}{2})^{2^{k-k_{0}+1}} \qquad &amp;\text{if }k&gt;k_{0}.
\end{cases}
\end{align}\)</p>
</blockquote>

<blockquote>
  <p>여기서 \(\gamma = \frac{\alpha \beta^{2}\eta^{2}m}{L^{2}}\), \(\eta = \min\{1, 3(1-2\alpha)\}\frac{m^{2}}{M}\), \(k_{0}\)는 \(\|\nabla f(x^{k_0+1}))\|_{2}&lt;\eta\)를 만족하기 시작하는 step이다.</p>
</blockquote>

<h2 id="proof-1-damped-phase">Proof 1. Damped phase</h2>
<p>먼저, \(\|\nabla f(x)\|_{2} \geq \eta\)를 만족하는 damped phase 부터 유도한다. 첫째로 backtracking line search 과정으로 결정되는 step size의 lower bound를 통하여 damped phase의 convergence를 유도하게 된다. 증명과정에서 Newton decrement의 관계식이 자주 활용된다.</p>

<blockquote>
  <p>\(f\)의 taylor approximation에서 \(y=x+t\Delta x_{nt}\)로 두고, Lipschitz condition의 upper bound로 적용한 아래 식에서부터 시작한다.</p>

\[\begin{align}
f(x+t\Delta x_{nt}) \leq f(x)+t\nabla f(x)^{T}\Delta x_{nt} + \frac{L \|\Delta x_{nt} \|^{2}_{2} }{2}t^{2},
\end{align}\]

  <p>Newton decrement, 증분과 hessian matrix와의 관계와 Strong convexity의 관계를 이용하여 다음과 같이 전개할 수 있다.</p>

\[\begin{align}
&amp;\text{ Since, }\lambda(x)^{2}=\Delta x_{nt}^{T} \nabla^{2} f(x) \geq m\|\Delta x_{nt}\|^{2}_{2},\\\\
&amp;f(x)+t\nabla f(x)^{T}\Delta x_{nt} + \frac{L \|\Delta x_{nt} \|^{2}_{2} }{2}t^{2} \leq f(x)-t\lambda(x)^{2} + \frac{L}{2m}t^{2}\lambda(x)^{2},
\end{align}\]

  <p>이 때, backtracking line search의 조건을 만족하기 위해서는 아래를 만족해야 한다.</p>

\[\begin{align}
f(x+t\Delta x_{nt}) \leq f(x)-(1-\frac{L}{2m}t)t \lambda(x)^{2}, \qquad \text{ where, }0&lt;1-\frac{L}{2m}t \leq \frac{1}{2}
\end{align}\]

  <p>위를 만족하는 t의 최소값을 \(\hat{t}\)라 할 때, \(\hat{t} = \frac{m}{L}\)이 되고, 이를 원 식에 대입하면 다음과 같다.</p>

\[\begin{align}
f(x+\hat{t}\Delta x_{nt})\leq f(x)-\frac{m}{2L}\lambda(x)^{2} \leq f(x) -\alpha \hat{t} \lambda(x)^{2},
\end{align}\]

  <p>backtracking line search에서 \(0&lt;\beta\leq 1\)이므로, \(t\geq \beta \frac{m}{L}\)를 만족하고, 이를 정리하여 최종 결과를 유도할 수 있다.</p>

\[\begin{align}
f(x^{+})-f(x) &amp;\leq -\alpha t \lambda(x)^{2}\\
&amp;\leq -\alpha\beta \frac{m}{L}\lambda(x)^{2}\\
&amp;\leq -\alpha\beta \frac{m}{L^{2}}\|\nabla f(x)\|^{2}_{2}\\
&amp;\leq -\alpha\beta \eta^{2}\frac{m}{L^{2}},\\
&amp;\gamma = \alpha\beta \eta^{2}\frac{m}{L^{2}}.
\end{align}\]
</blockquote>

<h2 id="proof-2-pure-phase">Proof 2. Pure phase</h2>
<p>이제 \(\|\nabla f(x)\|_{2} &lt; \eta\)일 때를 가정하고, Damped phase(quadratically convergent phase)를 살펴본다. 증명은 두가지 과정으로 나뉜다. backtracking line search의 t 업데이트가 필요하지 않음을 보이고, 수렴속도가 quadratic함을 보이게 된다.</p>

<blockquote>
  <p>Backtracking line seach로 부터 다음과 같은 식이 유도된다.</p>

\[\begin{align}
\eta \leq 3(1-2\alpha)\frac{m^{2}}{M}.
\end{align}\]

  <p>또한, Lipschitz conditon에 따라 \(t \geq 0\)에 대하여, 다음 조건을 만족한다.</p>

\[\begin{align}
\|\nabla^{2}f(x+t\Delta x_{nt})-\nabla^{2}f(x)\|_{2} \leq tM \|\Delta x_{nt} \|_{2},\\
| \Delta x_{nt}^{T} \big( \nabla^{2}f(x+t\Delta x_{nt})-\nabla^{2}f(x) \big) \Delta x_{nt}| \leq tM \|\Delta x_{nt} \|_{2}^{3}.
\end{align}\]

  <p>\(\tilde{f} = f(x+t\Delta x_{nt}\))라 두면, \(\tilde{f}''(t) = \Delta x_{nt}^{T} \nabla^{2}f(x+t\Delta x_{nt})\Delta x_{nt}\)이고, 이를 대입한다.</p>

\[\begin{align}
\tilde{f}''(t) \leq \tilde{f}''(0)+tM\|\Delta x_{nt}\|^{3}_{2} \leq tM\|\Delta x_{nt} \|^{3}_{2}
\end{align}\]

  <p>\(\tilde{f}''(0) = \lambda(x)^{2}\)이고, \(\lambda(x)^{2} \geq m\|\nabla x_{nt}\|_{2}^{2}\) 임을 이용하고, 부등식을 합친다. \(\tilde{f}'(0) = -\lambda(x)^{2}\)이므로 다음과 같이 정리할 수 있다.</p>

\[\begin{align}
\tilde{f}''(t) &amp;\leq \tilde{f}''(0) + tM \| \Delta x_{nt} \| ^{3}_{2} \leq \lambda(x)^{2} + t\frac{M}{m^{3/2}}\lambda(x)^{3}, \\
\tilde{f}'(t) &amp;\leq \tilde{f}'(0)+t\lambda(x)^{2} +t^{2}\frac{M}{2m^{3/2}}\lambda(x)^{3},\\
&amp;= -\lambda(x)^{2}+t\lambda(x)^{2} + t^{2}\frac{L}{2m^{3/2}}\lambda(x)^{3}.
\end{align}\]

  <p>이제 양변을 적분한다.</p>

\[\begin{align}
\tilde{f}(t) \leq \tilde{f}(0) - t\lambda(x)^{2} + t^{2} \frac{1}{2}\lambda(x)^{2} + t^{3}\frac{M}{6m^{3/2}}\lambda(x)^{3}.
\end{align}\]

  <p>t = 1로 두면, 아래와 같은 결과를 얻을 수 있다.</p>

\[\begin{align}
f(x+\Delta x_{nt}) \leq f(x) -\frac{1}{2}\lambda(x)^{2} + \frac{M}{6m^{3/2}}\lambda(x)^{3}.
\end{align}\]

  <p>이제 \(\|\nabla f(x)\|_{2}\leq \eta \leq 3(1-2\alpha)\frac{m^{2}}{M}\)이라 가정하면, strong convexity 조건에 의해 \(\lambda(x) \leq 3(1-2\alpha)m^{3/2}/L\)이다. 이를 위에 부등식에 대입하면 아래와 같은 결과를 유도할 수 있다.</p>

\[\begin{align}
f(x+\Delta x_{nt}) &amp;\leq f(x) - \lambda(x)^{2}( \frac{1}{2}- \frac{M\lambda(x)}{6m^{3/2}} ) \\
&amp;\leq f(x) -\alpha \lambda(x)^{2} \\
&amp;= f(x) + \alpha \nabla f(x)^{T} \Delta x_{nt},
\end{align}\]

  <p>이 결과는 \(t=1\)일때 backtracking line search를 수행하더라도 항상 조건을 만족하기 때문에, \(t\)를 감소시키지 않음을 의미한다.</p>
</blockquote>

<p>이제 우리는 수렴속도가 quadratic하게 줄어듬을 증명해본다.</p>
<blockquote>
  <p>\(x_{nt} = -(\nabla^{2}f(x))^{-1}\nabla f(x)\)임을 이용한 뒤, 적분의 성질 중 하나인 \(f(t, u) - f(t, v) = \int^{u}_{v}{\frac{\partial f}{\partial x}(t, x) dx}\)를 이용하여 정리하고, Hessian의 Lipschitz 조건을 적분식에 적용하고 정리한다. 마지막으로 strong convexity 조건을 적용하면 증명이 완료된다. 과정을 수식으로 나타내면 아래와 같다.</p>

\[\begin{align}
\| \nabla f(x^{+}) \| _{2} &amp;= \| \nabla f(x+\Delta x_{nt}) - \nabla f(x) - \nabla^{2}f(x)\Delta x_{nt} \|_{2}\\\\
&amp;=\| \int^{1}_{0}{ \big( \nabla^{2}f(x+t\Delta x_{nt})-\nabla^{2} f(x) \big) \Delta x_{nt} dt } \|_{2}\\\\
&amp; \leq \frac{M}{2}\|\Delta x_{nt} \|^{2}_{2}\\\\
&amp; = \frac{M}{2}\|\nabla^{2}f(x)^{-1}\nabla f(x)\|^{2}_{2}\\\\
&amp; \leq \frac{M}{2m^{2}}\|\nabla f(x)\|^{2}_{2}.
\end{align}\]
</blockquote>

<p>결론을 다시 정리하면, \(\eta = \min \{1, 3(1-2\alpha)\}\frac{m^{2}}{M}\) 일 때, \(\|\nabla f(x^{(k)}) \|_{2}&lt;\eta\)를 만족하는 조건에서는 Newton’s method는 backtracing line search에서의 업데이트가 더이상 필요하지 않고, quadratic하게 converge 한다.</p>

<h2 id="estimating-total-complexity">Estimating total complexity</h2>
<p>이제, 우리는 전체 과정에서의 complexity, 달리 말해 초기 값으로부터 최적값까지 도달하는데 걸리는 iteration 횟수에 대한 bound를 추정할 수 있다.
우선, 위의 damped Newton phase에서 \(f\)는 매 iteration마다 \(\gamma\)를 넘지 않는 선에서 값이 감소하므로, damped Newton step의 전체 step 수는 다음의 식의 결과값을 넘지 못한다.</p>
<blockquote>
\[\begin{align}
\frac{f(x^{(0)})-p^{\star}}{\gamma}.
\end{align}\]
</blockquote>

<p>pure Newton phase에서의 iteration 횟수의 bound 또한 계산할 수 있다. 위의 식을 \(f(x)-p^{\star}\leq \epsilon\), \(\epsilon_{0} = \frac{2m^{3}}{M^{2}}\)로 두고, iteration 횟수로 식을 정리하면 다음과 같은 값을 계산할 수 있다.</p>
<blockquote>
\[\begin{align}
&amp; &amp;\epsilon = \epsilon_{0} (\frac{1}{2})^{2^{k-k_{0}+1}}\\\\
&amp;\Leftrightarrow &amp;\frac{\epsilon_{0}}{\epsilon} = 2^{2^{k-k_{0}+1}}\\\\
&amp;\Leftrightarrow &amp;k-k_{0}+1 = log_{2}log_{2}(\frac{\epsilon_{0}}{\epsilon})
\end{align}\]
</blockquote>

<p>따라서 pure Newton phase에서 iteration 횟수는 \(\log \log(\frac{\epsilon_{0}}{\epsilon})\)로 bound 된다.</p>

<p>이 두 결과를 더하면, Newton method를 통하여 원하는 정밀도의 해를 얻는데 필요한 iteration 횟수의 upper bound를 정의할 수 있다.</p>
<blockquote>
\[\begin{align}
\frac{f(x^{(0)})-p^{\star}}{\gamma} + \log \log (\frac{\epsilon_{0}}{\epsilon}).
\end{align}\]
</blockquote>

<p>문제를 해결할때 요구되는 정밀도 \(\epsilon\)의 변화에 비해 우변의 두번째 항은 매우 작은 변화를 보이므로, 실제 응용에서는 이를 상수로 두고 추정을 하게 된다. 일반적으로 6번의 iteration은 \(\epsilon \approx 5\cdot 10^{-20}\epsilon_{0}\)의 정밀도를 보인다고 알려져 있다.</p>

<p>일반적으로 말해서, 목적함수 \(f\)를 최소화하는데 있어서 필요한 iteration 횟수는 다음과 같다.</p>
<blockquote>
\[\begin{align}
\frac{f(x^{(0)})-p^{\star}}{\gamma} + 6.
\end{align}\]
</blockquote>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_10"></a>14-06 Self concordance</h1>
            <p>앞서 살펴본 Newton’s method의 convergence analysis에서는 크게 두 가지의 단점이 존재한다. [1]</p>

<p>첫 번째로는, 현실상의 문제에서는 찾기 어려운 Lipschitz constant L, strong convexity의 lower bound, upper bound m, M 등이 수식에 포함되기 때문이다. 이 때문에, 수렴성과 수렴속도를 보일 수는 있지만, 구체적으로 해를 찾는 데 있어 얼마만큼의 Newton step이 필요한가 등의 분석은 거의 불가능하다.</p>

<p>두 번째로는, Newton’s method 자체는 affine invariant 하지만, Newton’s method의 convergence analysis에 있어서는 affine invariant 하지 않다. 이는 일반적인 함수에 대해서는 좌표축의 변화에 따라 Lipschitz constant나 strong convexity의 bound value들이 바뀌기 때문이다.</p>

<p>따라서 이 장에서는 위 두 가지 단점을 보완하는 Self-concordant function에 대해서 알아보고자 한다.</p>

<p>Self-concordant function이 중요하고, 의미 있는 이유는 크게 3가지로 정리할 수 있다.</p>

<ol>
  <li>뒷장에서 다룰 interior-point methods에 있어 중요한 역할을 하는 log barrier function들이 Self-concordant function에 속한다.</li>
  <li>Self-concordant function들의 Newton’s method analysis에서는 상수들에 대한 term이 존재하지 않는다.</li>
  <li>Self-concordance는 affine-invariant 하다. 즉, Newton’s method의 iteration 횟수 등의 추정에 있어, 좌표축의 affine transformation에 대하여 독립적이다.</li>
</ol>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_11"></a>14-06-01 Definition of self-concordant functions</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
    });
</script>

<h2 id="self-concordant-on-r">Self-concordant on \(R\)</h2>
<p>Convex 함수 \(f : R \rightarrow R\) 은 아래의 식을 만족할때 self-concordant 하다고 정의한다.</p>
<blockquote>
\[\begin{align}
\|f^{'''}(x)\| \leq 2f^{''}(x)^{3/2} \qquad \text{for all }x\in \text{dom }f.
\end{align}\]
</blockquote>

<p>쉬운 예시로, 선형 함수(\(ax+b\)), (convex한) 2차 함수는 3계도함수(3차 미분) 값이 0이므로, self-concordant하다.</p>

<h2 id="self-concordant-on-rn">Self-concordant on \(R^{n}\)</h2>
<p>\(f : R^{n}\rightarrow R\)은 정의역 안에서 임의의 방향의 선분 영역에 대하여, 다시 말해 정의역에 포함되는 모든 방향의 선분 영역에 대하여, self-concordant 할 때 이 함수를 self-concordant하다고 정의한다. 예를 들어, 모든 \(x\in dom\, f\) 와 모든 \(v\)에 대하여, \(g(t) = f(x+tv)\)로 정의될 떄, \(g(t)\)가 self-concordant하면, f를 domain of \(\mathbb{R}^{n}\)에서 self-concordant function이라고 정의한다.</p>

<h2 id="example-of-self-concordance-function">Example of self-concordance function</h2>

<p>1) \(f : \mathbb{R}^{n}_{++}\rightarrow \mathbb{R}\), \(f(x) = -\sum^{n}_{i=1}log(x_{i})\).</p>

<p>\(f(t) = -\log{t}\) 임은 쉽게 확인할 수 있다. 더불어 self-concordant 함수의 합 또한 self-concordant 함을 이용한다. Self-concordant한 함수 \(f_{1}, f_{2} : R\rightarrow R\)이 있다고 할 때, self-concordant 함수의 합 또한 self-concordant 함은 다음과 같이 보인다.[3]</p>
<blockquote>
\[\begin{align}
|f_{1}^{'''}(x)+f_{2}^{'''}(x)|  \leq &amp; |f^{'''}_{1}(x)|+|f^{'''}_{2}(x)|\\\\
\leq &amp;2\big( f^{''}_{1}(x)^{3/2}+f^{''}_{2}(x)^{3/2}\big)\\\\
\leq &amp;2\big( f^{''}_{1}(x)+f^{''}_{2}(x) \big)^{3/2}.
\end{align}\]
</blockquote>

<p>맨 마지막 단계의 경우 아래의 성질을 이용한다.</p>
<blockquote>
\[\begin{align}
(u^{3/2}+v^{3/2})^{2/3} \leq u+v, \qquad u, v \geq 0.
\end{align}\]
</blockquote>


        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_12"></a>14-06-02 Convergence analysis for self-concordant functions</h1>
            <p>Self-concordant function들에 대하여, Convergence analysis의 결과는 다음과 같다.</p>

<blockquote>
  <p>Theorem(Nestrov and Nemirovskii) : backtracking line search를 사용하는 Newton’s method는 \(f(x^{(k)})-f^{\star}\leq \epsilon\)에 도달함에 있어 아래 만큼의 iteration을 필요로 한다.
\begin{align}
C(\alpha, \beta)\big( f(x^{(0)}-f^{\star} \big) + \log\log{(1/\epsilon)},
\end{align}
여기서 \(C(\alpha, \beta)\)는 \(\alpha, \beta\)에 결정되는 상수이다.</p>
</blockquote>

<p>위의 과정에 대한 증명은 원래 Newton’s method에 대한 convergence anaylsis 증명과정과 유사하다. 다만 과정 중간에  self-concordant 성질을 이용하여 식들을 추가적으로 정리한다.([1]의 p.503)</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_13"></a>14-07 Comparison to first-order method</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
    });
</script>

<p>이 장에서는 개괄적인 관점에서 Newton’s method와 gradient descent를 비교해본다. 정의역의 dimension은 \(n\)이라 하자.</p>

<table>
  <thead>
    <tr>
      <th>항목</th>
      <th>Newton’s method</th>
      <th>Gradient descent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Memory</td>
      <td>\(O(n^{2})\)(\(n \times n\)의 hessian matrix) storage</td>
      <td>\(O(n)\)(\(n\)-dimensional gradient) storage</td>
    </tr>
    <tr>
      <td>Computation</td>
      <td>\(O(n^{3})\) flops(\(n \times n\)의 선형시스템 계산)</td>
      <td>\(O(n)\) flops(\(n\)-dimensional vector의 선형 결합)</td>
    </tr>
    <tr>
      <td>Backtracking</td>
      <td>\(O(n)\)</td>
      <td>\(O(n)\)</td>
    </tr>
    <tr>
      <td>Conditioning</td>
      <td>Affine invariant 등, conditioning에 크게 영향받지 않음</td>
      <td>큰 영향을 받을 가능성 존재</td>
    </tr>
    <tr>
      <td>Fragility</td>
      <td>bugs나 numerical errors에 민감</td>
      <td>newton’s method보다 비교적 강건</td>
    </tr>
  </tbody>
</table>

<h2 id="example">Example</h2>

<figure class="image" style="align: center;">
<p align="center">
 <img src="/convex-optimization/img/chapter_img/chapter14/gd(1).jpeg" alt="" width="70%" height="70%" />
 <figcaption style="text-align: center;">[Fig 1] Logistic regression [3]</figcaption>
</p>
</figure>

<p>위의 figure 1은 앞서 <a href="/convex-optimization/contents/chapter14/2021/03/26/14_04_backtracking_line_search/">14-04</a>에서 다룬 logistic regression 예시이다. x축을 실제로 연산에 걸린 시간으로 바꿔서 보면 다음과 같다. 
Convergence analysis에서 다룬 바와 같이 Newton’s method는 두가지 phase를 가진다. 그래프에서도 일정 시간 후, 빠른 수렴(quadratic convergence)을 보이는 것을 확인할 수 있다. iteration 초반부인 Newton’s method의 damped phase에서는 gradient descent와 동일한 scale의 수렴속도를 보인다. 하지만, \(O(n^{3})\)의 연산을 수행해야하기 떄문에 실제 연산시간 상에선 더 느린 수렴을 보인다. 이 후 backtracking line search가 더 이상 필요하지 않은 iteration에 도달하면, quadratic convergence의 속도를 보이며 매우 빠르게 수렴함을 확인할 수 있다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_14"></a>14-08 Special cases</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
    });
</script>

<h2 id="sparse-structured-problems">Sparse, structured problems</h2>
<p>우리가 해결하려는 문제의 linear system matrix가 \(O(n^{3})\)의 연산시간을 가지는 Hessian의 역행렬의 계산을 효과적으로 할 수 있는 조건을 만족하면, 우리는 이 문제를 좀 더 효율적으로 해결할 수 있다.</p>

<p>예를들어, \(\nabla^{2}f(x)\)가 모든 \(x\)에 대하여 sparse하고 structured 되어 있는 matrix 형태, 예를 들면 <a href="https://en.wikipedia.org/wiki/Band_matrix">band matrix</a>의 경우, Newton’s method를 적용하면서 memory와 computation에서 O(n)의 성능을 가진다. (Band matrix는 대각행과의 거리가 일정 범위 이내에 0이 아닌 항들이 모두 존재하는 형태, 즉 대각행 근처에만 값을 가지는 matrix를 의미한다.)</p>

<p>Structured Hessian을 만드는 대표적인 두가지 함수의 예를 알아보자.</p>

<ul>
  <li>
    <p>\(g(\beta) = f(X\beta)\)이면, \(\nabla^{2}g(\beta)=X^{T}\nabla^{2}f(X\beta)X\)이다. 또한 만약 X가 structured predictor matrix 이고 \(\nabla^{2}f\), 즉 \(f\)의 hessian이 digonal이면, \(\nabla^{2}g\)는 structured 되어있다.</p>
  </li>
  <li>
    <p>만약 \(\nabla^{2}f\)가 diagonal이고, \(g\)가 non smooth일때, \(f(\beta)+g(D\beta)\)를 최소화하고자 한다고 하자. 또한 \(D\)는 structured penalty matrix이다. 이때 Lagrange dual은 \(-f^{*}(-D^{T}u)-g^{*}(-u)\)이다. 일반적으로 \(-D\nabla^{2}f^{*}(-D^{T}u)D^{T}\)는 structured 될 수 있다.</p>
  </li>
</ul>

<h2 id="equality-constrained-newtons-method">Equality-constrained Newton’s method</h2>
<p>이제 등호 조건(equallity constraints)이 있는 최적화 문제를 살펴보자. 우리는 일반적으로 이 문제를 아래와 같이 나타내었다.</p>
<blockquote>
\[\begin{align}
&amp;\min_{x} f(x) &amp; \text{subject to }Ax=b.
\end{align}\]
</blockquote>

<p>이 문제의 해결에 대하여 크게 세가지 방법으로 접근해볼 수 있다.</p>

<p>1) 등호 조건의 제거(reduced-space approach) :  정의역 자체를 equality constraint를 만족하는 space로 제한하여 문제를 해결한다. 위의 문제라면, x를 A의 null space를 span하는 F와 \(Ax_{0}=b\)의 합으로 표현한다. 즉, \(x=Fy+x_{0}\)로 나타내고 y에 관하여 문제를 해결하는 방식이다.</p>

<p>2) 등호 제약조건을 만족하는 Newton’s method(Equality-constrained Newton)[4] : 기본적으로 unconstrained Newton’s method와 동일하나 두가지 차이가 있다. 첫째로는 초기값이 feasible해야하고(\(x \in dom (f)\)이고, \(Ax = b\))를 만족하고, 두 번째로는 Newton step의 과정에서 equality constraints를 고려한다는 것이다. 즉, Newton step \(\Delta x_{nt}\)를 \(A\Delta x_{nt}=0\)을 만족하도록 값을 결정한다. 아래에서 자세히 살펴보도록 한다.</p>

<p>3) Dual의 유도를 통한 해결 : Fenchel dual은 \(-f^{*}(-A^{T}v)-b^{T}v\)로 정의되고, strong duality를 만족한다. (<a href="/convex-optimization/contents/chapter16/2021/03/31/16_03_fenchel_duality/">16-03</a>에서 자세히 다루도록 한다.) 간략하게 conjugate function의 정의를 활용하여 dual 문제의 목적함수를 유도해보도록 하자. 여기서의 \(f^{*}\)는 f의 conjugate이다.</p>
<blockquote>
\[\begin{align}
g(v) &amp;= -b^{T}v + \min_{x}(f(x)+v^{T}Ax)\\\\
&amp;= -b^{T}v - \max_{x}\big( (-A^{T}v)^{T}x - f(x) \big)\\\\
&amp;= -b^{T}v - f^{*}(-A^{T}v),
\end{align}\]
</blockquote>

<p>이 되므로, dual 문제는 다음과 같다.</p>

<blockquote>
\[\begin{align}
\max -b^{T}v-f^{*}(-A^{T}v). 
\end{align}\]
</blockquote>

<p>최적값이 존재한다고 가정하기에, 이 문제는 strictly feasible하고, slater’s condition을 만족한다. 따라서 위에서 언급했듯이 strong duality를 만족하고, \(g(v^{*})=p^{*}\)인 \(v^{*}\)가 존재한다.[1, p.525]</p>

<p>이제 2)의 방법을 살펴보자.
feasible한 Newton step \(\Delta x_{nt}\)을 유도하기 위하여, 원래의 문제에서의 목적 함수를 x 근처의 2차 taylor 근사를 한 식으로 대체한다. 이를 나타내면 다음과 같다.</p>
<blockquote>
\[\begin{align}
\text{minimize}\quad &amp;\hat{f}(x+v) = f(x) + \nabla f(x)^{T}v + \frac{1}{2}v^{T}\nabla^{2} f(x) v\\\\
\text{subject to}\quad &amp;A(x+v) = b,
\end{align}\]
</blockquote>

<p>위의 식을 아래의 식으로도 표현할 수 있다.</p>
<blockquote>
\[\begin{align}
x^{+} = x + tv,\,\, \text{where}\\\\
v = \underset{A(x+z)=b}{\operatorname{argmin}}\big( f(x)+\nabla f(x)^{T}z+\frac{1}{2}z^{T}\nabla^{2} f(x)z \big)\\\\
\end{align}\]
</blockquote>

<p>\(Ax^{+} = Ax+tAv = b\)이므로, 
식을 반복하는 과정에서도 다음 스텝의 solution \(x\)가 계속 constraint 안에 존재하도록 유지한다.</p>

<p>이 문제에 대한 KKT를 아래와 같이 나타내고, linear system인 아래의 문제를 풀면 solution을 구할 수 있다. \(v\)가 Newton step \(\Delta x_{nt}\)임을 상기하자.</p>
<blockquote>
\[\begin{align}
\begin{bmatrix}
\nabla^{2} f(x) &amp; A^{T}\\\\
A &amp; 0
\end{bmatrix}
\begin{bmatrix}
v\\\\
w
\end{bmatrix}
=-
\begin{bmatrix}
\nabla f(x)\\\\
Ax-b
\end{bmatrix}
\end{align}\]
</blockquote>

<p>\(w\)는 위의 quadratic problem에 대한 optimal dual variable이다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_15"></a>14-09 Quasi-Newton methods</h1>
            <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: "center"
    });
</script>

<p>만약 우리가 구해야하는 Hessian의 연산량이 너무 크거나, singular한 경우, quasi-Newton method를 사용하여 Hessian matrix, 즉 \(\nabla^{2}f(x)\)를 \(H&gt;0\)로 근사할 수 있고, 이 \(H\)를 사용하여 update를 수행할 수 있다.</p>

<blockquote>
  <p>\begin{align}
x^{+} = x - tH^{-1}\nabla f(x)
\end{align}</p>
</blockquote>

<p>아래는 Quasi-Newton method의 특징이다. 조금 더 자세한 내용은 <a href="/convex-optimization/contents/chapter18/2021/03/23/18_00_Quasi_Newton_methods/">18장</a>에서 다룬다.</p>

<ul>
  <li>Hessian을 approximate하는 \(H\)는 매 스텝마다 갱신하여 계산된다. 목표는 \(H^{-1}\)을 비교적 적은 연산으로 구하여 적용하는 것이다.</li>
  <li>수렴속도가 superlinear로 빠르다. 하지만 Newton과 같은 수렴속도를 갖지는 않는다. 일반적으로 \(n\) steps의 quasi-Newton은 1 step의 Newton과 동일한 수렴의 크기를 보인다.</li>
  <li>많은 quasi-Newton methods는 iteration마다 \(H\)를 업데이트(propagate)해나가는 방식을 사용한다.</li>
</ul>

        </article>
    </div>
</main>




      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/convex-optimization/public/js/script.js'></script>
  </body>
</html>
