<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <style>
    .MathJax {
      padding: 2em 0.3em;
      overflow-x: auto;
      overflow-y: hidden;
    }
@media print {

    .container {
        padding: 0;
        max-width: unset;
        break-after: page;
        break-before: page;
    }
    .content {
        padding: 0;
    }
    .masthead {
        display: none;
    }
    .sidebar-toggle {
        display: none;
    }


}
  </style>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

  <title>
    
       Mixed Integer Programming 1 &middot; 모두를 위한 컨벡스 최적화
    
  </title>

  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="/public/css/github-markdown.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="122x144" href="https://convex-optimization-for-all.github.io/public/logo.png">
  <link rel="shortcut icon" href="https://convex-optimization-for-all.github.io/public/convex-logo-144x144.png">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://convex-optimization-for-all.github.io/atom.xml">

  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-189737072-1', 'auto');
    ga('send', 'pageview');
  </script>
  
</head>


  <body class="sidebar-overlay">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>모두를 위한 컨벡스 최적화</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/">Home</a>

    

    
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter01/">01. Introduction</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter02/">02. Convex Sets</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter03/">03. Convex Functions</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter04/">04. Convex Optimization Basis</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter05/">05. Canonical Problems</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter06/">06. Gradient Descent</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter07/">07. Subgradient</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter08/">08. Subgradient Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter09/">09. Proximal Gradient Descent and Acceleration</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter10/">10. Duality in Linear Programs</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter11/">11. Duality in General Programs</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter12/">12. KKT Conditions</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter13/">13. Duality uses and correspondences</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter14/">14. Newton's Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter15/">15. Barrier Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter16/">16. Duality Revisited</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter17/">17. Primal-Dual Interior-Point Methods</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter18/">18. Quasi-Newton Methods</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter19/">19. Proximal Netwon Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter20/">20. Dual Methods</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter21/">21. Alternating Direction Method of Mulipliers</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter22/">22. Conditional Gradient Method</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter23/">23. Coordinate Descent</a>
        
      
    
      
        
          <a class="sidebar-nav-item active" href="https://convex-optimization-for-all.github.io/contents/chapter24/">24.  Mixed Integer Programming 1</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/contents/chapter25/">25.  Mixed Integer Programming 2</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://convex-optimization-for-all.github.io/reference/">26. Reference</a>
        
      
    

    <span class="sidebar-nav-item">Currently v1.1.0</span>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2022. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap github-md-body">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">모두를 위한 컨벡스 최적화</a>
            <small></small>
          </h3>
          <a class="github-logo__wrapper" target="_blank" href="https://github.com/convex-optimization-for-all/convex-optimization-for-all.github.io" titltle="Github">
           <svg class="github-logo" xmlns="http://www.w3.org/2000/svg"  viewBox="0 0 48 48"><linearGradient id="rL2wppHyxHVbobwndsT6Ca" x1="4" x2="44" y1="23.508" y2="23.508" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#4c4c4c"/><stop offset="1" stop-color="#343434"/></linearGradient><path fill="url(#rL2wppHyxHVbobwndsT6Ca)" d="M24,4C12.954,4,4,12.954,4,24c0,8.887,5.801,16.411,13.82,19.016h12.36	C38.199,40.411,44,32.887,44,24C44,12.954,35.046,4,24,4z"/><path d="M30.01,41.996L30,36.198c0-0.939-0.22-1.856-0.642-2.687c5.641-1.133,8.386-4.468,8.386-10.177	c0-2.255-0.665-4.246-1.976-5.92c0.1-0.317,0.174-0.645,0.22-0.981c0.188-1.369-0.023-2.264-0.193-2.984l-0.027-0.116	c-0.186-0.796-0.409-1.364-0.418-1.388l-0.111-0.282l-0.111-0.282l-0.302-0.032l-0.303-0.032c0,0-0.199-0.021-0.501-0.021	c-0.419,0-1.04,0.042-1.627,0.241l-0.196,0.066c-0.74,0.249-1.439,0.485-2.417,1.069c-0.286,0.171-0.599,0.366-0.934,0.584	C27.334,12.881,25.705,12.69,24,12.69c-1.722,0-3.365,0.192-4.889,0.571c-0.339-0.22-0.654-0.417-0.942-0.589	c-0.978-0.584-1.677-0.819-2.417-1.069l-0.196-0.066c-0.585-0.199-1.207-0.241-1.626-0.241c-0.302,0-0.501,0.021-0.501,0.021	l-0.302,0.032l-0.3,0.031l-0.112,0.281l-0.113,0.283c-0.01,0.026-0.233,0.594-0.419,1.391l-0.027,0.115	c-0.17,0.719-0.381,1.615-0.193,2.983c0.048,0.346,0.125,0.685,0.23,1.011c-1.285,1.666-1.936,3.646-1.936,5.89	c0,5.695,2.748,9.028,8.397,10.17c-0.194,0.388-0.345,0.798-0.452,1.224c-0.197,0.067-0.378,0.112-0.538,0.137	c-0.238,0.036-0.487,0.054-0.739,0.054c-0.686,0-1.225-0.134-1.435-0.259c-0.313-0.186-0.872-0.727-1.414-1.518	c-0.463-0.675-1.185-1.558-1.992-1.927c-0.698-0.319-1.437-0.502-2.029-0.502c-0.138,0-0.265,0.01-0.376,0.028	c-0.517,0.082-0.949,0.366-1.184,0.78c-0.203,0.357-0.235,0.773-0.088,1.141c0.219,0.548,0.851,0.985,1.343,1.255	c0.242,0.133,0.765,0.619,1.07,1.109c0.229,0.368,0.335,0.63,0.482,0.992c0.087,0.215,0.183,0.449,0.313,0.732	c0.47,1.022,1.937,1.924,2.103,2.023c0.806,0.483,2.161,0.638,3.157,0.683l0.123,0.003c0,0,0.001,0,0.001,0	c0.24,0,0.57-0.023,1.004-0.071v2.613c0.002,0.529-0.537,0.649-1.25,0.638l0.547,0.184C19.395,43.572,21.645,44,24,44	c2.355,0,4.605-0.428,6.703-1.176l0.703-0.262C30.695,42.538,30.016,42.422,30.01,41.996z" opacity=".05"/><path d="M30.781,42.797c-0.406,0.047-1.281-0.109-1.281-0.795v-5.804c0-1.094-0.328-2.151-0.936-3.052	c5.915-0.957,8.679-4.093,8.679-9.812c0-2.237-0.686-4.194-2.039-5.822c0.137-0.365,0.233-0.75,0.288-1.147	c0.175-1.276-0.016-2.086-0.184-2.801l-0.027-0.116c-0.178-0.761-0.388-1.297-0.397-1.319l-0.111-0.282l-0.303-0.032	c0,0-0.178-0.019-0.449-0.019c-0.381,0-0.944,0.037-1.466,0.215l-0.196,0.066c-0.714,0.241-1.389,0.468-2.321,1.024	c-0.332,0.198-0.702,0.431-1.101,0.694C27.404,13.394,25.745,13.19,24,13.19c-1.762,0-3.435,0.205-4.979,0.61	c-0.403-0.265-0.775-0.499-1.109-0.699c-0.932-0.556-1.607-0.784-2.321-1.024l-0.196-0.066c-0.521-0.177-1.085-0.215-1.466-0.215	c-0.271,0-0.449,0.019-0.449,0.019l-0.302,0.032l-0.113,0.283c-0.009,0.022-0.219,0.558-0.397,1.319l-0.027,0.116	c-0.169,0.715-0.36,1.524-0.184,2.8c0.056,0.407,0.156,0.801,0.298,1.174c-1.327,1.62-1.999,3.567-1.999,5.795	c0,5.703,2.766,8.838,8.686,9.806c-0.395,0.59-0.671,1.255-0.813,1.964c-0.33,0.13-0.629,0.216-0.891,0.256	c-0.263,0.04-0.537,0.06-0.814,0.06c-0.69,0-1.353-0.129-1.69-0.329c-0.44-0.261-1.057-0.914-1.572-1.665	c-0.35-0.51-1.047-1.417-1.788-1.755c-0.635-0.29-1.298-0.457-1.821-0.457c-0.11,0-0.21,0.008-0.298,0.022	c-0.366,0.058-0.668,0.252-0.828,0.534c-0.128,0.224-0.149,0.483-0.059,0.708c0.179,0.448,0.842,0.85,1.119,1.002	c0.335,0.184,0.919,0.744,1.254,1.284c0.251,0.404,0.37,0.697,0.521,1.067c0.085,0.209,0.178,0.437,0.304,0.712	c0.331,0.719,1.353,1.472,1.905,1.803c0.754,0.452,2.154,0.578,2.922,0.612l0.111,0.002c0.299,0,0.8-0.045,1.495-0.135v3.177	c0,0.779-0.991,0.81-1.234,0.81c-0.031,0,0.503,0.184,0.503,0.184C19.731,43.64,21.822,44,24,44c2.178,0,4.269-0.36,6.231-1.003	C30.231,42.997,30.812,42.793,30.781,42.797z" opacity=".07"/><path fill="#fff" d="M36.744,23.334c0-2.31-0.782-4.226-2.117-5.728c0.145-0.325,0.296-0.761,0.371-1.309	c0.172-1.25-0.031-2-0.203-2.734s-0.375-1.25-0.375-1.25s-0.922-0.094-1.703,0.172s-1.453,0.469-2.422,1.047	c-0.453,0.27-0.909,0.566-1.27,0.806C27.482,13.91,25.785,13.69,24,13.69c-1.801,0-3.513,0.221-5.067,0.652	c-0.362-0.241-0.821-0.539-1.277-0.811c-0.969-0.578-1.641-0.781-2.422-1.047s-1.703-0.172-1.703-0.172s-0.203,0.516-0.375,1.25	s-0.375,1.484-0.203,2.734c0.077,0.562,0.233,1.006,0.382,1.333c-1.31,1.493-2.078,3.397-2.078,5.704	c0,5.983,3.232,8.714,9.121,9.435c-0.687,0.726-1.148,1.656-1.303,2.691c-0.387,0.17-0.833,0.33-1.262,0.394	c-1.104,0.167-2.271,0-2.833-0.333s-1.229-1.083-1.729-1.813c-0.422-0.616-1.031-1.331-1.583-1.583	c-0.729-0.333-1.438-0.458-1.833-0.396c-0.396,0.063-0.583,0.354-0.5,0.563c0.083,0.208,0.479,0.521,0.896,0.75	c0.417,0.229,1.063,0.854,1.438,1.458c0.418,0.674,0.5,1.063,0.854,1.833c0.249,0.542,1.101,1.219,1.708,1.583	c0.521,0.313,1.562,0.491,2.688,0.542c0.389,0.018,1.308-0.096,2.083-0.206v3.75c0,0.639-0.585,1.125-1.191,1.013	C19.756,43.668,21.833,44,24,44c2.166,0,4.243-0.332,6.19-0.984C29.585,43.127,29,42.641,29,42.002v-5.804	c0-1.329-0.527-2.53-1.373-3.425C33.473,32.071,36.744,29.405,36.744,23.334z M11.239,32.727c-0.154-0.079-0.237-0.225-0.185-0.328	c0.052-0.103,0.22-0.122,0.374-0.043c0.154,0.079,0.237,0.225,0.185,0.328S11.393,32.806,11.239,32.727z M12.451,33.482	c-0.081,0.088-0.255,0.06-0.389-0.062s-0.177-0.293-0.096-0.381c0.081-0.088,0.255-0.06,0.389,0.062S12.532,33.394,12.451,33.482z M13.205,34.732c-0.102,0.072-0.275,0.005-0.386-0.15s-0.118-0.34-0.016-0.412s0.275-0.005,0.386,0.15	C13.299,34.475,13.307,34.66,13.205,34.732z M14.288,35.673c-0.069,0.112-0.265,0.117-0.437,0.012s-0.256-0.281-0.187-0.393	c0.069-0.112,0.265-0.117,0.437-0.012S14.357,35.561,14.288,35.673z M15.312,36.594c-0.213-0.026-0.371-0.159-0.353-0.297	c0.017-0.138,0.204-0.228,0.416-0.202c0.213,0.026,0.371,0.159,0.353,0.297C15.711,36.529,15.525,36.62,15.312,36.594z M16.963,36.833c-0.227-0.013-0.404-0.143-0.395-0.289c0.009-0.146,0.2-0.255,0.427-0.242c0.227,0.013,0.404,0.143,0.395,0.289	C17.381,36.738,17.19,36.846,16.963,36.833z M18.521,36.677c-0.242,0-0.438-0.126-0.438-0.281s0.196-0.281,0.438-0.281	c0.242,0,0.438,0.126,0.438,0.281S18.762,36.677,18.521,36.677z"/></svg>
          </a>
        </div>
      </div>

      <div class="container content">
        <h1>24.  Mixed Integer Programming 1</h1>






<!-- Get first post and show it -->

<p>이 장에서는 Mixed Integer Programming의 정의, 관련 예제를 소개하고, Integer programming 의 해를 찾기 위해서 간접적으로 relaxation 을 활용하여 최적해를 찾아나가는 방식을 소개한다.</p>


<!-- Remove first element from post_list which is already shown above. -->
  

<!-- List up the posts in the chapter -->
<ul style="list-style: none;">

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_1">24-01 Definition</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_2">24-02 Examples of integer programs</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_3">24-03 Solving integer programs</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_4">24-04 Relaxations</a>
    </li>
  
  

  
  
  
  
    <li style="text-align:left; vertical-align: middle; margin-left: -2em; margin-top: 5px;" >
      <a href="#_page_5">24-05 Branch and bound algorithm (B&B)</a>
    </li>
  
  

</ul>


<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_1"></a>24-01 Definition</h1>
            <p>이 절에서는 Mixed integer program 방식을 통해서 Optimization problem 을 풀기 위한 기본 개념들에 대해 설명하고자 한다.</p>

<h2 id="problem-definition">Problem definition</h2>
<p>Optimization model 중 일부 변수(variables)가 정수(integer)라는 제한조건이 있을 때, 이를 integer program 이라 부른다.</p>
<blockquote>
  <p>\(\begin{align}
&amp;\min_{x} &amp;&amp; f(x) \\\\
&amp;\text{subject to } &amp;&amp; x \in C \\\\
&amp;&amp;&amp;x_{j} \in \mathbb{Z}, j \in J
\end{align}\)
\(\begin{align}
\text{where } f: \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \subseteq \mathbb{R}^{n} \quad and \quad J \subseteq {1, \dotsc, n}. 
\end{align}\)</p>
</blockquote>

<p>앞선 식에서 \(J\)가 다음을 만족 한다면, pure integer program 이라고 부른다.</p>
<blockquote>
  <p>\(J =\) { \(1, \dotsc, n\) }</p>
</blockquote>

<p>이 절에서 논의되는 \(f\) 와 \(C\) 는 모두 convex라고 가정하도록 하자.</p>

<h2 id="binary-variables">Binary variables</h2>
<p>Integer program을 대표하는 몇몇 사례를 살펴보면 yes/no 결정 문제 또는 논리값등을 들 수 있다.
이때 이진변수(binary variable)를 사용해서 문제를 정의하면서 조건에 대한 0 혹은 1의 값을 구해 문제를 풀게 된다.</p>

<p>다음으로 소개할 Combinatorial optimization은 integer program과 직접적으로 연관되어 있다. binary variable을 활용함으로써, 기존 문제를 재변형하여 새로운 문제로 바꿔 풀 수 있기 때문이다.</p>

<p>Combinatorial optimization problem은 triple \((N, \mathcal{F}, c)\) 표현을 활용하여 정의된다.<br /></p>
<blockquote>
  <ul>
    <li>\(\quad N\) 은 유한한 ground set 이다<br /></li>
    <li>\(\quad \mathcal{F} \subseteq 2^{N}\) 는 feasible solution들의 집합이다<br /></li>
    <li>\(\quad c \in \mathbb{R}^{N}\) 은 cost function 이다<br /></li>
  </ul>
</blockquote>

<p>triple \((N, \mathcal{F}, c)\) 를 통해서 다음 수식을 푸는 것이 최종 목표이다.</p>

<blockquote>
\[\begin{align}
\quad \min_{S \in \mathcal{F}} &amp; \sum_{i \in S} c_{i} \\
\end{align}\]
</blockquote>

<p>많은 결합 최적화(combinatorial optimization) 문제는 binary integer program들로 쓰여질 수있다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_2"></a>24-02 Examples of integer programs</h1>
            <p>이번 절에서는 Integer program에 해당하는 다양한 예시들을 살펴보면서 어떻게 활용되는지 감을 익혀보자.</p>

<h2 id="knapsack-problem">Knapsack problem</h2>
<p>배낭 문제(Knapsack problem)은 배낭에 넣을 수 있는 부피가 한정되어 있어 배낭 안에 들어갈 item의 총 크기가 제약되어 있을 때, 최대의 가치(value)를 가지는 item들을 선택하도록 문제를 푸는 전통적인 조합 최적화 문제이다. 이 문제는 binary variable \(x\)로 표현이 가능한데, \(j\)번째 item을 선택했는 지 아닌지에 따라 \(x_{j}\)가 0 혹은 1의 값을 가지게 된다.</p>

<blockquote>
\[\begin{align}
&amp;\max_{x} &amp;&amp; c^\intercal x \\\\
&amp;\text{subject to } &amp;&amp; a^\intercal x \leq b \\\\
&amp;&amp;&amp;x_{j} \in {0, 1}, j = 1, \dotsc , n
\end{align}\]
</blockquote>

<p>\(c_{j}, a_{j}\) 는 각각 \(j\)번째 item의 가치(value) 와 크기(volume) 를 나타낸다.</p>

<h2 id="assignment-problem">Assignment problem</h2>
<p>\(n\)명의 사람들과 \(n\)개의 업무가 있다고 가정하자. 그리고 각각의 사람은 정확히 한가지의 업무에만 배당 가능하다. 여기서  \(c_{ij}\)는 사람 \(i\)가 업무 \(j\)를 수행하는 데 소요되는 비용을 의미하는데, Assignment problem은 가장 적은 비용으로 \(n\)명의 사람들을 \(n\)개의 업무를 할당하는 것을 목표로 한다. 이 때의 조건을 최적화 하기 위하여 수식으로 표현하면 다음과 같다.</p>

<blockquote>
\[\begin{align}
&amp;\min_{x} &amp;&amp;\sum_{i = 1}^{n} \sum_{j = 1}^{n} c_{ij} x_{ij} \\\\
&amp;\text{subject to } &amp;&amp;\sum_{i = 1}^{n} x_{ij} = 1, j = 1 \dotsc n \\\\
&amp;&amp;&amp;\sum_{i = 1}^{n} x_{ij} = 1, j = 1 \dotsc n \\\\
&amp;&amp;&amp;x_{ij} \in \lbrace 0, 1\rbrace \quad i = 1 \dotsc n, \quad j = 1 \dotsc n
\end{align}\]
</blockquote>

<h2 id="facility-location-problem">Facility location problem</h2>
<p>Facility location problem은 특정 시설로부터 고객까지 운송 비용을 최소화하는 것을 목표로 하는 문제이다.<br /></p>

<p>\(N = \lbrace 1, \dotsc, n \rbrace\) 의 창고(depot)가 존재하고, \(M = \lbrace 1, \dotsc, m \rbrace\) 의 고객이 있다고 가정하자.<br />
고정된 비용 \(f_{j}\)는 창고 \(j\)의 사용과 연관되어 있다.
운송 비용 \(c_{ij}\)는 고객 \(i\)에게 배송되는 물품이 창고 \(j\)로 부터 운송될 때 발생하는 비용이다.<br /></p>

<p>여기서 결정해야 하는 사항은 어떤 창고가 운용가능하며 어떤 고객이 각각의 창고로부터 배송을 받을 수 있는지에 대한 것으로, 고정 비용과 운송 비용을 최소화하는 쪽으로 수식을 유도해 푸는 것이다.</p>

<blockquote>
\[\begin{align}
&amp;\min_{x, y} &amp;&amp; \sum_{i = 1}^{n} f_{j} y_{j} + \sum_{i = 1}^{m} \sum_{j = 1}^{n} c_{ij} x_{ij} \\
&amp;\text{subject to } &amp;&amp; \sum_{j = 1}^{n} x_{ij} = 1,  \quad i = 1 \dotsc n \\
&amp;&amp;&amp; x_{ij} \leq y_{j},  \quad i = 1 \dotsc m,  \quad j = 1 \dotsc n \\
&amp;&amp;&amp; x_{ij} \in \lbrace 0, 1\rbrace \quad i = 1 \dotsc n, \quad j = 1 \dotsc n \\
&amp;&amp;&amp; y_{j} \in \lbrace 0, 1\rbrace \quad j = 1 \dotsc n \\
\end{align}\]
</blockquote>

<p>첫번째 제약조건은, 각각의 고객은 하나의 창고로부터 물품을 배송받을 수 있음을 의미한다. 두번째 제약조건은 창고  \(j\)가 운영되고 있어야 고객 \(i\)가 그 곳으로 부터 물품을 배송받을 수 있다는 것을 말한다. 이 때, \(x_{ij}\)와 \(y_{j}\)가 모두 binary 이기 때문에 \(mn\) constranint 를 생각할 수 있다. 이는 “marginalized” 형식으로 다음과 같이 제약조건으로 표현할 수도 있다.</p>

<blockquote>
\[\sum_{i = 1}^{n} x_{ij} \leq m y_{j}, \quad j = 1 \dotsc n\]
</blockquote>

<p>이를 반영하여 다음과 같은 수식으로 대체할 수 있다.</p>

<blockquote>
\[\begin{align}
&amp;\min_{x, y} &amp;&amp;\sum_{i = 1}^{n} f_{j} y_{j} + \sum_{i = 1}^{m} \sum_{j = 1}^{n} c_{ij} x_{ij} \\
&amp;\text{subject to } &amp;&amp;\sum_{j = 1}^{n} x_{ij} = 1,  \quad i = 1 \dotsc n \\
&amp;&amp;&amp; \sum_{i = 1}^{n} x_{ij} \leq m y_{j}, \quad j = 1 \dotsc n \\
&amp;&amp;&amp; x_{ij} \in \lbrace 0, 1\rbrace \quad i = 1 \dotsc n, \quad j = 1 \dotsc n \\
&amp;&amp;&amp; y_{j} \in \lbrace 0, 1\rbrace \quad j = 1 \dotsc n \\
\end{align}\]
</blockquote>

<h2 id="k-means-and-k-medoids-clustering">K-means and K-medoids clustering</h2>
<p>군집(clustering)은 데이터를 유사한 그룹으로 나누는 것으로, K-means 알고리즘은 군집 내의 데이터 포인트들 간의 거리를 평균으로 \(K\)개의 중심값(centroid)을 찾아 K개의 군집을 찾는 문제로,  partition \(S_{1} \cup \dotsc \cup S_{K} = \lbrace 1, \dotsc, n \rbrace\) 를 주어진 데이터에서 찾는 것을 목표로 한다. 이 때 다음 수식을 최소화 한다.</p>

\[\sum_{i = 1}^{K} \sum_{j \in S_{i}} \| x^{(j)} - \mu^{(i)} \|^{2}\]

<p>where \(\mu^{(i)} :  = \frac{1}{| S_{i} |} \sum_{j \in S_{i}} x^{(i)}\),
\(\mu^{(i)}\) 는 cluster \(i\)의 centroid를 의미한다.</p>

<p>평균을 계산해서 centroid를 구하는 것 (K-means) 보다 좀 더 Outlier에 Robust한 방법은 K개의 군집의 중심값을 산술평균으로 구하는 대신 군집의 중심에 가장 가까운 하나의 데이터 포인트를 중심값으로 정하는 방법 (K-medoids clustering) 이다. 
즉, 각각의 data point (\(y^{(i)}\))를 중심점으로 생각하고 이를 계산하였을 때 최소값이 나올 수 있는 data point를 centroid로 지정하는 방법 (K-medoids clustering) 이다.</p>

<blockquote>
  <p>\(\sum_{i = 1}^{K} \sum_{j \in S_{i}} \| x^{(j)} - y^{(i)} \|^{2}\)
\(\text{where } y^{(i)} \in \lbrace x^{(j)} : j \in S_{i} \rbrace\)</p>
</blockquote>

<p><br />
이 문제는 integer program으로 변형하여 나타내어 질 수 있다.
먼저,  \(d_{ij} = \| x^{(i)} - x^{(j)} \|^2\) 를 정의하고, 다음 두 가지의 binary variable을 정의 한다.</p>

\[\begin{align}
&amp;w_{i} =\begin{cases}1 &amp;&amp; \text{if choose } x^{(i)} \text{ as a centroid} \\\\
0 &amp;&amp; \text{otherwise.} \end{cases}\\\\
&amp;z_{ji} =\begin{cases}1 &amp;&amp; \text{if } x^{(j)} \text{ in the cluster with centroid } x^{(i)} \\\\ 
0 &amp;&amp; \text{otherwise.} \end{cases} 
\end{align}\]

<p><br /></p>

<p>K-medoids 문제는 optimization problem으로 정의하면 다음과 같다.</p>

<blockquote>
\[\begin{align}
&amp;\min_{w, z} &amp;&amp; \sum_{i = 1}^{n} \sum_{j = 1}^{n} d_{ij} z_{ji} \\\\
&amp;\text{subject to } &amp;&amp; z_{ji} \leq w_{i} \\\\
&amp;&amp;&amp; \sum_{i = 1}^{n} w_{i} = k \\\\
&amp;&amp;&amp; w_{ij} \in 0, 1 \quad i = 1 \dotsc n \\\\
&amp;&amp;&amp; z_{ji} \in 0, 1 \quad j, i = 1 \dotsc n
\end{align}\]
</blockquote>

<p>첫번째 제약조건은 centroid가 먼저 정해지고 난 후, $x_{i}$에 대한 $x_{j}$가 있는 지 없는 지 판별하겠다는 것을 의미한다.</p>

<h2 id="best-subset-selection">Best subset selection</h2>
<p>\(X = [x^{1} \quad \dotsc \quad x^{p}] \in \mathbb{R}^{n×p}, \quad y \in \mathbb{R}^{n}\) 조건이 주어졌을 때, Best subset selection 문제는 다음과 같다.</p>

<blockquote>
  <p>\(\begin{align}
&amp;\min_{\beta} &amp;&amp;\frac{1}{2} \| y - X\beta \|^{2} \\\\
&amp;\text{subject to } &amp;&amp;\| \beta \| \leq k\\\\
\end{align}\)
\(\begin{align}
\text{where}  \| \beta \|_{0}  :  = \text{ the number of nonzero entries of } \beta.
\end{align}\)</p>
</blockquote>

<p>\(\| \beta \|_{0}\)는 Non-convex constraint 이기 때문에 Integer programing 으로 변형해서 문제를 풀면 좀 더 수월하게 풀 수 있다.</p>

<blockquote>
\[\begin{align}
&amp;\min_{\beta, z} &amp;&amp; \frac{1}{2} \| y - X\beta \|^{2} \\\\
&amp;\text{subject to } &amp;&amp; | \beta_{i} | \leq Mz_{i} \quad i = 1 \dotsc n \\\\
&amp;&amp;&amp;z_{ji} \in \lbrace 0, 1 \rbrace \quad i = 1 \dotsc n \\\\
&amp;&amp;&amp;\sum_{i = 1}^{p} z_{i} \leq k
\end{align}\]
</blockquote>

<h2 id="least-median-of-squares-regression">Least median of squares regression</h2>
<p>\(X = [x^{1} \quad \dotsc \quad x^{p}] \in \mathbb{R}^{n×p}, \quad y \in \mathbb{R}^{n}\), 그리고 \(\beta \in \mathbb{R}^{p}\) 조건이 주어졌을 때, \(r : = y - X\beta\) 로 정의하면, Least median of squares regression 문제는 다음과 같다.</p>

<blockquote>
\[\beta_{LMS} : = \arg\min_{\beta} (median | r_{i} | ).\]
</blockquote>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_3"></a>24-03 Solving integer programs</h1>
            <p>Integer program으로 수식을 변형한 뒤, 문제를 해결하려면 relaxation과 같은 기법이 필요하다. integer programs에서 나타나는 제약 사항 및 문제에 대해 어떤 접근을 하는 지 살펴보도록 하자.</p>

<h2 id="hardness-of-integer-programs">Hardness of integer programs</h2>
<p>Integer program 문제를 푸는 것은 convex optimization 문제를 푸는 것보다 훨씬 어렵다. 일반적인 Integer programming은 풀 수 있는 가능성 조차도 모르면서 최소 polynomial time이 걸리는 <a href="https://en.wikipedia.org/wiki/NP-hardness">NP-hard</a> 이기 때문이다. 이 때, integer constaint에 대한 제약을 없앰으로써 convex relaxation을 하면, optimal value에 다가가는 lower bound를 구할 수 있다.<br /><br />
Convex relaxation은 사용하여 문제를 풀면 다음과 같은 한계가 발생할 수 있다.</p>

<ul>
  <li>Feasible integer solution을 구하는 것이 어렵게 될 수 있다.</li>
  <li>Relaxation 조건에서 얻어진 optimal solution이 integer program으로 얻어지는 optimal solution과 거리가 있을 수 있다.</li>
  <li>근사(Rounding)를 했을 때의 값이 optimal 값과 다를 수 있다.</li>
</ul>

<h2 id="algorithmic-template-for-solving-integer-programs">Algorithmic template for solving integer programs</h2>
<p>\(X\)가 convex 이고 integrality constraints를 포함할 때, integer program은 다음과 같다.</p>

<blockquote>
\[z : = \min_{x \in X} f(x)\]
</blockquote>

<p>Convex optimization과 다르게 feasible point \(x* \in X\)가 optimal 이라는 것을 입증하는 직접적인 “optimality conditions”는 존재하지 않는다. 대신에, lower bound \(\underline{z} \leq z\), 그리고 upper bound \(\bar{z} \geq z\) 를 찾아가면서 \(\underline{z} = \bar{z}\) 에 가까워지도록 optimal의 근사치를 찾는 방법을 사용 할 수 있다.</p>

<h4 id="algorithmic-template">Algorithmic template</h4>
<p>Upper bounds의 감소 시퀀스를 관찰하면,</p>
<blockquote>
\[\bar{z_1} \geq \bar{z_2} \geq \dotsc \bar{z_s} \geq z\]
</blockquote>

<p>lower bounds의 증가 시퀀스를 관찰하면,</p>
<blockquote>
\[\underline{z_1} \leq \underline{z_2} \leq \dotsc \underline{z_t} \leq z\]
</blockquote>

<p>임의의 \(\epsilon &gt; 0\)에 대하여 \(\underline{z_1} - \bar{z_t} \leq \epsilon\) 이 되는 범위에서 \(z\)의 값이 정해진다.</p>

<h4 id="primal-bounds">Primal bounds</h4>
<p>앞선 \(z\) 공식에 따라 임의의 feasible \(x \in X\)에서 항상 \(f(x) \geq z\)가 성립하고, 이 때, \(f(x)\)는 upper bound 이다. 하지만 항상 feasible \(x\)를 찾을 수는 없기 때문에, \(x\)값이 해당 셋에 포함 된다면 문제가 쉽게 풀리지만, 그렇지 않을 수도 있다.</p>

<h4 id="dual-bounds">Dual bounds</h4>
<p>보통 lower bounds 로도 불리며, relaxation을 통해서 그 값을 찾게 된다. 다음 장에서 자세한 설명을 덧붙인다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_4"></a>24-04 Relaxations</h1>
            <p>Relaxation을 위해서는 특정 조건이 성립이 되어야 하며, Convex relaxation과 Lagrangian relaxation 방법을 활용할 수 있다. 자세한 내용을 살펴보도록 하자.</p>

<h2 id="conditions-for-relaxations">Conditions for Relaxations</h2>
<p>일반적인 optimization problem이 다음과 같이 정의된다면,</p>
<blockquote>
\[\min_{x \in X} f(x)\]
</blockquote>

<p>이 문제의 relaxation은 임의의 optimization problem으로 나타내었을 때, 다음과 같이 정의된다.</p>

<blockquote>
\[\begin{align}
&amp;\min_{x \in Y} \: g(x)\\\\
&amp;\text{such that}\\\\
&amp;\text{① } X \subset Y \quad \text{ and}\\\\ 
&amp;\text{② } g(x) \leq f(x) \text{ for all } x \in X 
\end{align}\]
</blockquote>

<p>목적함수 \(f(x)\) 와 \(g(x)\)가 달라지면 두 조건 모두 만족해야 하고, 같다면 조건 ①만 만족해도 될 것이다.
두 조건에 의하여, relaxation에서의 optimal value는 original problem에서의 optimal value의 lower bound가 된다.</p>

<h2 id="convex-relaxations">Convex relaxations</h2>
<p>주어진 문제가 다음과 같을 때,</p>
<blockquote>
  <p>\(\begin{align}
&amp;\min_{x} &amp;&amp;f(x) \\\\
&amp;\text{subject to } &amp;&amp; x \in C \\\\
&amp;&amp;&amp;x_j \in \mathbb{Z}, \quad j \in J \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f : \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\quad \text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)</p>
</blockquote>

<p>convex relaxation을 아래와 같이 표현할 수 있다.</p>
<blockquote>
  <p>\(\begin{align}
&amp;\min_{x} &amp;&amp; f(x) \\\\
&amp;\text{subject to } &amp;&amp; x \in C \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f: \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)</p>
</blockquote>

<h2 id="lagrangian-relaxations">Lagrangian relaxations</h2>
<p>\(X\)가 convex 그리고 integer constraints를 모두 포함할 때, 다음과 같이 문제를 정의 할 수 있다.</p>

<blockquote>
\[\begin{align}
&amp;\min_{x} &amp;&amp;f(x) \\\\
&amp;\text{subject to } &amp;&amp;Ax \leq b \\\\
&amp;&amp;&amp; x_{j} \in \mathbb{Z} \quad x \in X 
\end{align}\]
</blockquote>

<p>이 때, constraints를 objective에 더하여, 어떤 \(u \geq 0\)에 대한 Lagrangian relaxation을 하면, 다음과 같다.</p>

<blockquote>
\[\begin{align}
L(u) = &amp;\min_{x} &amp;&amp;f(x) + u^{\top}(Ax-b) \\\\
&amp;\text{subject to } &amp;&amp;x \in X
\end{align}\]
</blockquote>

<p>Lagrangian form을 통해서 constraint set이 확장되었고, feasible \(x\)에 대해 \(Ax \leq b\)을 만족하므로, 항상 \(f(x) + u^{\top}(Ax - b) \leq f(x), u \geq 0\)이 성립한다. 따라서 \(L(u)\)는 임의의 \(u \geq 0\)에 대해서 lower bound이고, 최선의 lower bound는 dual problem \(\max_{u \geq 0} L(u)\)을 해결함으로써 얻어낼 수 있다. \(L(u)\)는 convex function의 point-wise minimization이기 때문에 concave optimization problem이 된다는 것을 기억하자.</p>

<p>앞서 언급되었던 Facility location problem에 Lagrangian relaxation을 적용해 보면, unconstrained \(v\)에 대하여 다음 식을 푸는 문제로 변형된다.</p>

<blockquote>
\[\begin{align}
L(u) = &amp;\min_{x} &amp;&amp; \sum_{i = 1}^{n} f_{j}y_{j} + \sum_{i = 1}^{m}\sum_{j = 1}^{n}(c_{ij} - v_{i})x_{ij} + \sum_{i = 1}^{m} v_{i} \\\\
&amp;\text{subject to } &amp;&amp; x_{ij} \leq y_{j} \quad i = 1 \dotsc m, \quad j = 1 \dotsc n \\\\
&amp;&amp;&amp; x_{ij}, y_{j} \in \lbrace 0, 1 \rbrace \quad  i = 1 \dotsc m, \quad j = 1 \dotsc n 
\end{align}\]
</blockquote>

<p>각각의 \(v\)에 대하여 Lagrange relaxation \(L(v)\)는 쉽게 풀릴 수 있다 :</p>
<blockquote>
  <p>\(x_{ij}(v) =\begin{cases}1 &amp; \text{if} \quad c_{ij} - v_{i} &lt; 0 \quad \text{and}  \quad \sum_{l} (c_{lj} - v_{l})^{-} + f_{j} &lt; 0 \\\\
0 &amp; \text{otherwise.} \end{cases}\)
\(y_{j}(v) =\begin{cases}1 &amp; \text{if } \quad \sum_{l} (c_{lj} - v_{l})^{-} + f_{j} &lt; 0 \\\\
0 &amp; \text{otherwise.} \end{cases}\)</p>
</blockquote>

<p>이는 lower bound \(L(v)\) 그리고 heuristic primal solution을 도출 할 수 있도록 한다. 또한 \(-L(v)\)의 부분미분(subdifferential)을 사용한다면 계산도 쉬워진다. subgradient method를 사용하여 \(\max_{v} L(v)\)를 \(\min_{v} -L(v)\) 로 변환시켜서 문제를 풀어갈 수 있다.</p>

        </article>
    </div>
</main>

<main class="container">
    <div class="content">
        <article class="post-body">
            <h1><a name="_page_5"></a>24-05 Branch and bound algorithm (B&B)</h1>
            <p>Branch and bound 알고리즘과 Convex relaxation 을 통해 Integer program을 풀어가는 방법을 알아보자.</p>

<h2 id="definition-and-properties">Definition and properties</h2>
<p>Branch and bound 알고리즘은 integer program을 푸는 가장 보편적인 방법이다. 주로 divide and conquer 방식으로 원래의 문제를 여러 개의 작은 문제(sub-problems)로 쪼개서 정답에 접근해나가는 방식이다.</p>

<p>Constraint set \(X = X_{1} \cup X_{1} \cup \dotsc \cup X_{k}\) 가 각각의 \(X_{i}\)로 이루어진 partition의 합집합일 때,</p>
<blockquote>
\[\min_{x \in X} f(x) = \min_{i = 1, \dotsc , k} \lbrace \min_{x \in X_{i}} f(x) \rbrace .\]
</blockquote>

<p>영역을 분할하여 minimum을 찾아나가면서 최적의 해를 구할 수 있다.</p>

<p>Sub-problem의 임의의 feasible solution을 upper bound \(u(X)\)로 정할 수 있다. lower bound를 얻기 위해서, 각각의 sub-problem에서의 lower bound \(l(X_{i})\) 를 구한다. 그리고 나서 만약 \(l(X_{i}) \geq u(X)\) 일 경우에 이 부분에 해당하는 sub-problem \(\min_{x \in X_{i}} f(x)\) 을 제외한다.</p>

<p>Integer Programming problem (IP) 문제를 다음과 같이 정의한다.</p>

<blockquote>
  <p>\(\begin{align}
&amp;\min_{x} &amp;&amp;f(x) \\\\
&amp;\text{subject to } &amp;&amp; x \in C \\\\
&amp;&amp;&amp;x_j \in \mathbb{Z}, \quad j \in J \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f : \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\quad \text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)</p>
</blockquote>

<p>그리고 Convex Relaxation (CR) 문제가 다음과 같을 때,</p>

<blockquote>
  <p>\(\begin{align}
&amp;\min_{x} &amp;&amp;f(x) \\\\
&amp;\text{subject to } &amp;&amp;x \in C \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f : \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\quad \text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)</p>
</blockquote>

<p>recursive하게 문제를 풀어간다.</p>

<ul>
  <li>Constraint set이 trivial 하다면, (CR) 문제를 푼다. 만약 solution이 현재 upper bound 보다 적다면, upper bound를 업데이트 한다. Stop.
    <ul>
      <li>(CR) 이 infeasible 하다면, (IP) 역시 infeasible 하다. Stop.</li>
      <li>(CR) 에서의 해 \(x^{\star}\)가 (IP) 에서도 feasible 하다면, \(x^{\star}\)는 해가 된다. Stop.</li>
    </ul>
  </li>
  <li>문제에서의 lower bound를 찾는다.
    <ul>
      <li>(CR) 에서의 해 \(x^{\star}\)가 (IP) 에서는 infeasible 하다면, (IP) 에서의 lower bound 를 갱신한다.</li>
    </ul>
  </li>
  <li>Lower bound가 현재의 upper bound보다 크다면, Stop.</li>
  <li>Constraint set을 쪼갠다, 그리고 각각의 sub-problem을 recursive하게 푼다.</li>
</ul>

<h2 id="after-branching">After branching</h2>

<ul>
  <li>Branching 이후에 각각의 subproblem을 푼다.</li>
  <li>만약에 subproblem의 lower bound가 현재의 upper bound보다 크다면, 그 하부의 subproblem을 고려할 필요가 없다.</li>
  <li>Lower bound를 계산하는 가장 확실한 방법은 convex relaxation을 거쳐서 구하는 것이지만, 다른 방법들 (e.g., Lagrangian relaxation) 또한 사용되기도 한다.</li>
</ul>

        </article>
    </div>
</main>




      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/public/js/script.js'></script>
  </body>
</html>
